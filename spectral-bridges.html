<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.52">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Félix Laplante">
<meta name="author" content="Christophe Ambroise">
<meta name="dcterms.date" content="2025-07-06">
<meta name="keywords" content="spectral clustering, vector quantization, scalable, non-parametric">
<meta name="description" content="This document provides a template based on the quarto system for contributions to Computo. The github repository in itself provides a specific quarto extension useful for authors (and editors!).">

<title>Spectral Bridges</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="spectral-bridges_files/libs/clipboard/clipboard.min.js"></script>
<script src="spectral-bridges_files/libs/quarto-html/quarto.js"></script>
<script src="spectral-bridges_files/libs/quarto-html/popper.min.js"></script>
<script src="spectral-bridges_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="spectral-bridges_files/libs/quarto-html/anchor.min.js"></script>
<link href="spectral-bridges_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="spectral-bridges_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="spectral-bridges_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="spectral-bridges_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="spectral-bridges_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="spectral-bridges_files/libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="spectral-bridges_files/libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: #FFFFFF;
      }

      .quarto-title-block .quarto-title-banner {
        color: #FFFFFF;
background: #034E79;
      }
</style>
<meta name="quarto:status" content="draft">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="citation_title" content="Spectral Bridges">
<meta name="citation_keywords" content="spectral clustering,vector quantization,scalable,non-parametric">
<meta name="citation_author" content="Félix Laplante">
<meta name="citation_author" content="Christophe Ambroise">
<meta name="citation_publication_date" content="2025-07-06">
<meta name="citation_cover_date" content="2025-07-06">
<meta name="citation_year" content="2025">
<meta name="citation_online_date" content="2025-07-06">
<meta name="citation_fulltext_html_url" content="https://github.com/cambroise/spectral-bridges-computo">
<meta name="citation_doi" content="10.xxxx/xxx-xxx">
<meta name="citation_issn" content="2824-7795">
<meta name="citation_language" content="en">
<meta name="citation_journal_title" content="Computo">
<meta name="citation_reference" content="citation_title=Estimating the number of clusters in a data set via the gap statistic;,citation_author=Robert Tibshirani;,citation_author=Guenther Walther;,citation_author=Trevor Hastie;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=2;,citation_volume=63;,citation_journal_title=Journal of the Royal Statistical Society: Series B (Statistical Methodology);,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=UMAP: Uniform manifold approximation and projection;,citation_author=Leland McInnes;,citation_author=John Healy;,citation_author=Nathaniel Saul;,citation_author=Lukas Großberger;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.21105/joss.00861;,citation_issue=29;,citation_doi=10.21105/joss.00861;,citation_volume=3;,citation_journal_title=Journal of Open Source Software;,citation_publisher=The Open Journal;">
<meta name="citation_reference" content="citation_title=Self-tuning spectral clustering;,citation_author=Lihi Zelnik-Manor;,citation_author=Pietro Perona;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=17;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=On spectral clustering: Analysis and an algorithm;,citation_author=Andrew Ng;,citation_author=Michael Jordan;,citation_author=Yair Weiss;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_volume=14;,citation_journal_title=Advances in neural information processing systems;">
<meta name="citation_reference" content="citation_title=Elements of information theory;,citation_author=Thomas M. Cover;,citation_author=Joy A. Thomas;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_isbn=978-0-471-06259-2;">
<meta name="citation_reference" content="citation_title=Cluster validity methods: Part i;,citation_author=Maria Halkidi;,citation_author=Yannis Batistakis;,citation_author=Michalis Vazirgiannis;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=2;,citation_volume=31;,citation_journal_title=ACM SIGMOD Record;,citation_publisher=ACM New York, NY, USA;">
<meta name="citation_reference" content="citation_title=Information theory and the stock market;,citation_author=Thomas M Cover;,citation_author=Joy A Thomas;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_journal_title=Elements of Information Theory. Wiley Inc., New York;">
<meta name="citation_reference" content="citation_title=Hierarchical grouping to optimize an objective function;,citation_author=Joe H Ward Jr;,citation_publication_date=1963;,citation_cover_date=1963;,citation_year=1963;,citation_issue=301;,citation_volume=58;,citation_journal_title=Journal of the American Statistical Association;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Finite mixture models;,citation_author=Geoffrey J. McLachlan;,citation_author=David Peel;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_isbn=9780471006268;">
<meta name="citation_reference" content="citation_title=Clustering with block mixture models;,citation_author=Gérard Govaert;,citation_author=Mohamed Nadif;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=2;,citation_volume=36;,citation_journal_title=Pattern Recognition;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Kernel k-means, spectral clustering and normalized cuts;,citation_author=Inderjit S Dhillon;,citation_author=Yuqiang Guan;,citation_author=Brian Kulis;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=Proceedings of the tenth ACM SIGKDD international conference on knowledge discovery and data mining;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=K-means++: The advantages of careful seeding;,citation_abstract=The k-means method is a widely used clustering technique that seeks to minimize the average squared distance between points in the same cluster. Although it offers no accuracy guarantees, its simplicity and speed are very appealing in practice. By augmenting k-means with a simple, randomized seeding technique, we obtain an algorithm that is $O(\log k)$-competitive with the optimal clustering. Experiments show our augmentation improves both the speed and the accuracy of k-means, often quite dramatically.;,citation_author=David Arthur;,citation_author=Sergei Vassilvitskii;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_fulltext_html_url=http://ilpubs.stanford.edu:8090/778/;,citation_technical_report_institution=Stanford InfoLab; Stanford;,citation_technical_report_number=2006-13;">
<meta name="citation_reference" content="citation_title=Normalized cuts and image segmentation;,citation_author=Jianbo Shi;,citation_author=Jitendra Malik;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=8;,citation_volume=22;,citation_journal_title=IEEE Transactions on Pattern Analysis and Machine Intelligence;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Maximum likelihood from incomplete data via the EM algorithm;,citation_author=Arthur P Dempster;,citation_author=Nan M Laird;,citation_author=Donald B Rubin;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_issue=1;,citation_volume=39;,citation_journal_title=Journal of the Royal Statistical Society: Series B (Methodological);,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Integrated genomic analysis identifies clinically relevant subtypes of glioblastoma characterized by abnormalities in PDGFRA, IDH1, EGFR, and NF1;,citation_author=Roel G. W. Verhaak;,citation_author=Katherine A. Hoadley;,citation_author=Elizabeth Purdom;,citation_author=Victoria Wang;,citation_author=Yuexin Qi;,citation_author=Matthew D. Wilkerson;,citation_author=Charlie R. Miller;,citation_author=Li Ding;,citation_author=Todd Golub;,citation_author=Jill P. Mesirov;,citation_author=Gabriela Alexe;,citation_author=Michael Lawrence;,citation_author=Michael O’Kelly;,citation_author=Pablo Tamayo;,citation_author=Bruce A. Weir;,citation_author=Stacey Gabriel;,citation_author=Wendy Winckler;,citation_author=Shubhada Gupta;,citation_author=Henrik Bengtsson;,citation_author=Lakshmi Jakkula;,citation_author=Heidi S. Feiler;,citation_author=Jennifer G. Hodgson;,citation_author=Christopher D. James;,citation_author=Jann N. Sarkaria;,citation_author=Cameron Brennan;,citation_author=Arnold Kahn;,citation_author=Paul T. Spellman;,citation_author=Richard K. Wilson;,citation_author=Terence P. Speed;,citation_author=Joe W. Gray;,citation_author=Matthew Meyerson;,citation_author=Gad Getz;,citation_author=Charles M. Perou;,citation_author=D. Neil Hayes;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=1;,citation_volume=17;,citation_journal_title=Cancer Cell;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Cluster analysis and display of genome-wide expression patterns;,citation_author=Michael B. Eisen;,citation_author=Paul T. Spellman;,citation_author=Patrick O. Brown;,citation_author=David Botstein;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=25;,citation_volume=95;,citation_journal_title=Proceedings of the National Academy of Sciences;,citation_publisher=National Acad Sciences;">
<meta name="citation_reference" content="citation_title=Overlapping stochastic block models with application to the French political blogosphere;,citation_author=Pierre Latouche;,citation_author=Etienne Birmelé;,citation_author=Christophe Ambroise;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=https://doi.org/10.1214/10-AOAS382;,citation_issue=1;,citation_doi=10.1214/10-AOAS382;,citation_volume=5;,citation_journal_title=The Annals of Applied Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Adaptive mixtures of local experts;,citation_author=Robert A Jacobs;,citation_author=Michael I Jordan;,citation_author=Steven J Nowlan;,citation_author=Geoffrey E Hinton;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=1;,citation_volume=3;,citation_journal_title=Neural computation;,citation_publisher=MIT Press;">
<meta name="citation_reference" content="citation_title=Git: Clustering based on graph of intensity topology;,citation_author=Zhangyang Gao;,citation_author=Haitao Lin;,citation_author=Cheng Tan;,citation_author=Lirong Wu;,citation_author=Stan Li;,citation_author=others;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2110.01274;">
<meta name="citation_reference" content="citation_title=Large scale spectral clustering via landmark-based sparse representation;,citation_author=Deng Cai;,citation_author=Xinlei Chen;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=8;,citation_volume=45;,citation_journal_title=IEEE transactions on cybernetics;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Parallel spectral clustering in distributed systems;,citation_author=Wen-Yen Chen;,citation_author=Yangqiu Song;,citation_author=Hongjie Bai;,citation_author=Chih-Jen Lin;,citation_author=Edward Y Chang;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=3;,citation_volume=33;,citation_journal_title=IEEE transactions on pattern analysis and machine intelligence;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Ultra-scalable spectral clustering and ensemble clustering;,citation_author=Dong Huang;,citation_author=Chang-Dong Wang;,citation_author=Jian-Sheng Wu;,citation_author=Jian-Huang Lai;,citation_author=Chee-Keong Kwoh;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=6;,citation_volume=32;,citation_journal_title=IEEE Transactions on Knowledge and Data Engineering;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Support-vector networks;,citation_author=Corinna Cortes;,citation_author=Vladimir Vapnik;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_issue=3;,citation_volume=20;,citation_journal_title=Machine learning;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Computo: Reproducible computational/algorithmic contributions in statistics and machine learning;,citation_author=Computo Team;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=computo;">
<meta name="citation_reference" content="citation_title=R: A language and environment for statistical computing;,citation_author=R Core Team;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://www.R-project.org/;">
<meta name="citation_reference" content="citation_title=Reticulate: Interface to python;,citation_author=Kevin Ushey;,citation_author=JJ Allaire;,citation_author=Yuan Tang;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://github.com/rstudio/reticulate;">
<meta name="citation_reference" content="citation_title=Python: An ecosystem for scientific computing;,citation_author=Fernando Perez;,citation_author=Brian E Granger;,citation_author=John D Hunter;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=2;,citation_volume=13;,citation_journal_title=Computing in Science
&amp;amp;amp; Engineering;,citation_publisher=AIP Publishing;">
<meta name="citation_reference" content="citation_title=Some methods for classification and analysis of multivariate observations;,citation_author=James MacQueen;,citation_author=others;,citation_publication_date=1967;,citation_cover_date=1967;,citation_year=1967;,citation_volume=1;,citation_conference_title=Proceedings of the fifth berkeley symposium on mathematical statistics and probability;,citation_conference=Oakland, CA, USA;">
<meta name="citation_reference" content="citation_title=On a class of repulsive mixture models;,citation_abstract=Finite or infinite mixture models are routinely used in Bayesian statistical practice for tasks such as clustering or density estimation. Such models are very attractive due to their flexibility and tractability. However, a common problem in fitting these or other discrete models to data is that they tend to produce a large number of overlapping clusters. Some attention has been given in the statistical literature to models that include a repulsive feature, i.e., that encourage separation of mixture components. We study here a method that has been shown to achieve this goal without sacrificing flexibility or model fit. The model is a special case of Gibbs measures, with a parameter that controls the level of repulsion that allows construction of d-dimensional probability densities whose coordinates tend to repel each other. This approach was successfully used for density regression in Quinlan et al. (J Stat Comput Simul 88(15):2931–2947, 2018). We detail some of the global properties of the repulsive family of distributions and offer some further insight by means of a small simulation study.;,citation_author=José J. Quinlan;,citation_author=Fernando A. Quintana;,citation_author=Garritt L. Page;,citation_publication_date=2021-06-01;,citation_cover_date=2021-06-01;,citation_year=2021;,citation_fulltext_html_url=https://doi.org/10.1007/s11749-020-00726-y;,citation_issue=2;,citation_doi=10.1007/s11749-020-00726-y;,citation_issn=1863-8260;,citation_volume=30;,citation_journal_title=TEST;">
<meta name="citation_reference" content="citation_title=A stochastic PCA and SVD algorithm with an exponential convergence rate;,citation_abstract=We describe and analyze a simple algorithm for principal component analysis and singular value decomposition, VR-PCA, which uses computationally cheap stochastic iterations, yet converges exponentially fast to the optimal solution. In contrast, existing algorithms suffer either from slow convergence, or computationally intensive iterations whose runtime scales with the data size. The algorithm builds on a recent variance-reduced stochastic gradient technique, which was previously analyzed for strongly convex optimization, whereas here we apply it to an inherently non-convex problem, using a very different analysis.;,citation_author=Ohad Shamir;,citation_editor=Francis Bach;,citation_editor=David Blei;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_fulltext_html_url=https://proceedings.mlr.press/v37/shamir15.html;,citation_volume=37;,citation_conference_title=Proceedings of the 32nd international conference on machine learning;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Approche probabiliste en classification automatique et contraintes de voisinage;,citation_author=Christophe Ambroise;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_dissertation_institution=Compiègne;">
<meta name="citation_reference" content="citation_title=The self-organizing map;,citation_author=Teuvo Kohonen;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_issue=9;,citation_volume=78;,citation_journal_title=Proceedings of the IEEE;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=A tutorial on spectral clustering;,citation_author=Ulrike Von Luxburg;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=17;,citation_journal_title=Statistics and computing;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=A density-based algorithm for discovering clusters in large spatial databases with noise;,citation_author=Martin Ester;,citation_author=Hans-Peter Kriegel;,citation_author=Jörg Sander;,citation_author=Xiaowei Xu;,citation_author=others;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_volume=96;,citation_conference_title=Kdd;">
<meta name="citation_reference" content="citation_title=The art of writing a scientific article;,citation_author=J. Geer;,citation_author=J. A. J. Hanraads;,citation_author=R. A. Lupton;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_volume=163;,citation_journal_title=J. Sci. Commun.;">
<meta name="citation_reference" content="citation_title=The elements of style;,citation_author=W. Strunk Jr.;,citation_author=E. B. White;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;">
<meta name="citation_reference" content="citation_title=How to prepare an electronic version of your article;,citation_author=G. R. Mettam;,citation_author=L. B. Adams;,citation_editor=B. S. Jones;,citation_editor=R. Z. Smith;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_inbook_title=Introduction to the electronic age;">
</head>

<body><div id="quarto-draft-alert" class="alert alert-warning"><i class="bi bi-pencil-square"></i>Draft</div>

<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title"><a href="https://computo.sfds.asso.fr">
        <img src="https://computo.sfds.asso.fr/assets/img/logo_notext_white.png" height="60px">
      </a> &nbsp; Spectral Bridges</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> source</button></div></div>
            <p class="subtitle lead">Scalable Spectral Clustering Based on Vector Quantization</p>
            <p><a href="http://creativecommons.org/licenses/by/4.0/"><img src="https://i.creativecommons.org/l/by/4.0/80x15.png" alt="Creative Commons BY License"></a>
ISSN 2824-7795</p>
            <div>
        <div class="description">
          <p>This document provides a template based on the quarto system for contributions to Computo. The github repository in itself provides a specific quarto extension useful for authors (and editors!).</p>
        </div>
      </div>
                </div>
  </div>
    
    <div class="quarto-title-meta-author">
      <div class="quarto-title-meta-heading">Authors</div>
      <div class="quarto-title-meta-heading">Affiliations</div>
          
          <div class="quarto-title-meta-contents">
        Félix Laplante 
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  Université de Paris Saclay
                </p>
            </div>
            <div class="quarto-title-meta-contents">
        <a href="https://computo.sfds.asso.fr">Christophe Ambroise</a> <a href="https://orcid.org/0000-0002-8148-0346" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
      </div>
          
          <div class="quarto-title-meta-contents">
              <p class="affiliation">
                  Université Paris-Saclay, CNRS, Univ Evry,
                </p>
            </div>
        </div>
                    
  <div class="quarto-title-meta">
                                
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 6, 2025</p>
      </div>
    </div>
                                    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">November 15, 2024</p>
      </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Doi</div>
      <div class="quarto-title-meta-contents">
        <p class="doi">
          <a href="https://doi.org/10.xxxx/xxx-xxx">10.xxxx/xxx-xxx</a>
        </p>
      </div>
    </div>
                  
      <div>
      <div class="quarto-title-meta-heading">Keywords</div>
      <div class="quarto-title-meta-contents">
        <p class="date">spectral clustering, vector quantization, scalable, non-parametric</p>
      </div>
    </div>
    
    <div>
      <div class="quarto-title-meta-heading">Status</div>
      <div class="quarto-title-meta-contents">
              <p class="date">draft</p>
                  </div>
    </div>

  </div>
                                                
  <div>
    <div class="abstract">
    <div class="abstract-title">Abstract</div>
      <p>In this paper, Spectral Bridges, a novel clustering algorithm, is introduced. This algorithm builds upon the traditional k-means and spectral clustering frameworks by subdividing data into small Voronoï regions, which are subsequently merged according to a connectivity measure. Drawing inspiration from Support Vector Machine’s margin concept, a non-parametric clustering approach is proposed, building an affinity margin between each pair of Voronoï regions. This approach delineates intricate, non-convex cluster structures and is robust to hyperparameter choice.</p>
      <p>The numerical experiments underscore Spectral Bridges as a fast, robust, and versatile tool for clustering tasks spanning diverse domains. Its efficacy extends to large-scale scenarios encompassing both real-world and synthetic datasets.</p>
      <p>The Spectral Bridge algorithm is implemented both in Python (<a href="https://pypi.org/project/spectral-bridges" class="uri">https://pypi.org/project/spectral-bridges</a>) and R <a href="https://github.com/cambroise/spectral-bridges-Rpackage" class="uri">https://github.com/cambroise/spectral-bridges-Rpackage</a>).</p>
    </div>
  </div>

  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#related-work" id="toc-related-work" class="nav-link" data-scroll-target="#related-work"><span class="header-section-number">2</span> Related Work</a></li>
  <li><a href="#spectral-bridges" id="toc-spectral-bridges" class="nav-link" data-scroll-target="#spectral-bridges"><span class="header-section-number">3</span> Spectral Bridges</a>
  <ul class="collapse">
  <li><a href="#sec-bridge-affinity" id="toc-sec-bridge-affinity" class="nav-link" data-scroll-target="#sec-bridge-affinity"><span class="header-section-number">3.1</span> Bridge affinity</a></li>
  <li><a href="#algorithm" id="toc-algorithm" class="nav-link" data-scroll-target="#algorithm"><span class="header-section-number">3.2</span> Algorithm</a></li>
  <li><a href="#hyperparameter-settings" id="toc-hyperparameter-settings" class="nav-link" data-scroll-target="#hyperparameter-settings"><span class="header-section-number">3.3</span> Hyperparameter settings</a></li>
  </ul></li>
  <li><a href="#numerical-experiments" id="toc-numerical-experiments" class="nav-link" data-scroll-target="#numerical-experiments"><span class="header-section-number">4</span> Numerical experiments</a>
  <ul class="collapse">
  <li><a href="#datasets" id="toc-datasets" class="nav-link" data-scroll-target="#datasets"><span class="header-section-number">4.1</span> Datasets</a>
  <ul class="collapse">
  <li><a href="#real-world-data" id="toc-real-world-data" class="nav-link" data-scroll-target="#real-world-data"><span class="header-section-number">4.1.1</span> Real-world data</a></li>
  <li><a href="#synthetic-data" id="toc-synthetic-data" class="nav-link" data-scroll-target="#synthetic-data"><span class="header-section-number">4.1.2</span> Synthetic data</a></li>
  <li><a href="#datasets-summary-class-balance" id="toc-datasets-summary-class-balance" class="nav-link" data-scroll-target="#datasets-summary-class-balance"><span class="header-section-number">4.1.3</span> Datasets Summary &amp; Class Balance</a></li>
  </ul></li>
  <li><a href="#metrics" id="toc-metrics" class="nav-link" data-scroll-target="#metrics"><span class="header-section-number">4.2</span> Metrics</a></li>
  <li><a href="#platform" id="toc-platform" class="nav-link" data-scroll-target="#platform"><span class="header-section-number">4.3</span> Platform</a></li>
  <li><a href="#sensitivity-to-hyperparameters" id="toc-sensitivity-to-hyperparameters" class="nav-link" data-scroll-target="#sensitivity-to-hyperparameters"><span class="header-section-number">4.4</span> Sensitivity to hyperparameters</a></li>
  <li><a href="#time-complexity" id="toc-time-complexity" class="nav-link" data-scroll-target="#time-complexity"><span class="header-section-number">4.5</span> Time complexity</a></li>
  <li><a href="#accuracy" id="toc-accuracy" class="nav-link" data-scroll-target="#accuracy"><span class="header-section-number">4.6</span> Accuracy</a></li>
  <li><a href="#noise-robustness" id="toc-noise-robustness" class="nav-link" data-scroll-target="#noise-robustness"><span class="header-section-number">4.7</span> Noise robustness</a></li>
  </ul></li>
  <li><a href="#conclusive-remarks" id="toc-conclusive-remarks" class="nav-link" data-scroll-target="#conclusive-remarks"><span class="header-section-number">5</span> Conclusive remarks</a></li>
  
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="spectral-bridges.pdf"><i class="bi bi-file-pdf"></i>PDF (computo)</a></li></ul></div></nav>
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Clustering is a fundamental technique for exploratory data analysis, organizing a set of objects into distinct homogeneous groups known as clusters. It is extensively utilized across various fields, such as biology for gene expression analysis <span class="citation" data-cites="Eisen1998">(<a href="#ref-Eisen1998" role="doc-biblioref">Eisen et al. 1998</a>)</span>, social sciences for community detection in social networks <span class="citation" data-cites="latouche2011">(<a href="#ref-latouche2011" role="doc-biblioref">Latouche, Birmelé, and Ambroise 2011</a>)</span>, and psychology for identifying behavioral patterns. Clustering is often employed alongside supervised learning as a pre-processing step, helping to structure and simplify data, thus enhancing the performance and interpretability of subsequent predictive models <span class="citation" data-cites="Verhaak2010">(<a href="#ref-Verhaak2010" role="doc-biblioref">Verhaak et al. 2010</a>)</span>. Additionally, clustering can be integrated into supervised learning algorithms, such as mixture of experts <span class="citation" data-cites="jacobs1991adaptive">(<a href="#ref-jacobs1991adaptive" role="doc-biblioref">Jacobs et al. 1991</a>)</span>, as part of a multi-objective strategy.</p>
<p>There are various approaches to clustering, and the quality of the results is largely determined by how the similarity between objects is defined, either through a similarity measure or a distance metric. Clustering techniques originate from diverse fields of research, such as genetics, psychometry, statistics, and computer science. Some methods are entirely heuristic, while others aim to optimize specific criteria and can be related to statistical models.</p>
<!--This diversity reflects the multidisciplinary nature of clustering, incorporating insights and methodologies from multiple scientific disciplines.
-->
<p>Density-based methods identify regions within the data with a high concentration of points, corresponding to the modes of the joint density. A notable non-parametric example of this approach is DBSCAN <span class="citation" data-cites="ester1996density">(<a href="#ref-ester1996density" role="doc-biblioref">Ester et al. 1996</a>)</span>. In contrast, model-based clustering, such as Gaussian mixture models, represents a parametric approach to density-based methods. Model-based clustering assumes that the data is generated from a mixture of underlying probability distributions, typically Gaussian distributions. Each cluster is viewed as a component of this mixture model, and the Expectation-Maximization (EM) algorithm is often used to estimate the parameters. This approach provides a probabilistic framework for clustering, allowing for the incorporation of prior knowledge and the ability to handle more complex cluster shapes and distributions <span class="citation" data-cites="mclachlan2000finite">(<a href="#ref-mclachlan2000finite" role="doc-biblioref">McLachlan and Peel 2000</a>)</span>.</p>
<p>Geometric approaches, such as k-means <span class="citation" data-cites="macqueen1967some">(<a href="#ref-macqueen1967some" role="doc-biblioref">MacQueen et al. 1967</a>)</span>, are distance-based methods that aim to partition data by optimizing a criterion reflecting group homogeneity. The k-means++ algorithm <span class="citation" data-cites="arthur2007kmeanspp">(<a href="#ref-arthur2007kmeanspp" role="doc-biblioref">Arthur and Vassilvitskii 2006</a>)</span> enhances this approach by providing faster and more reliable results. However, a key limitation of these methods is the assumption of linear boundaries between clusters, implying that clusters are convex. To address non-convex clusters, the kernel trick can be applied, allowing for a more flexible k-means algorithm. This approach is comparable to spectral clustering in handling complex cluster boundaries <span class="citation" data-cites="dhillon2004kernel">(<a href="#ref-dhillon2004kernel" role="doc-biblioref">Dhillon, Guan, and Kulis 2004</a>)</span>. The k-means algorithm can also be interpreted within the framework of model-based clustering under specific assumptions <span class="citation" data-cites="govaert2003clustering">(<a href="#ref-govaert2003clustering" role="doc-biblioref">Govaert and Nadif 2003</a>)</span>, revealing that it is essentially a special case of the more general Gaussian mixture models, where clusters are assumed to be spherical Gaussian distributions with equal variance.</p>
<p>Graph-based methods represent data as a graph, with vertices symbolizing data points and edges weighted to indicate the affinity between these points. Spectral clustering can be seen as a relaxed version of the graph cut algorithm <span class="citation" data-cites="shi2000normalized">(<a href="#ref-shi2000normalized" role="doc-biblioref">Shi and Malik 2000</a>)</span>. However, traditional spectral clustering faces significant limitations due to its high time and space complexity, greatly hindering its applicability to large-scale problems <span class="citation" data-cites="von2007tutorial">(<a href="#ref-von2007tutorial" role="doc-biblioref">Von Luxburg 2007</a>)</span>.</p>
<p>The method we propose aims to find non-convex clusters in large datasets, without relying on a parametric model, by using spectral clustering based on an affinity that characterizes the local density of the data. The algorithm described in this paper draws from numerous clustering approaches. The initial intuition is to detect high-density areas. To this end, vector quantization is used to divide the space into a Voronoï tessellation. An original geometric criterion is then employed to detect pairs of Voronoï regions that are either distant from each other or separated by a low-density boundary. Finally, this affinity measure is considered as the weight of an edge in a complete graph connecting the centroids of the tessellation, and a spectral clustering algorithm is used to find a partition of this graph. The only parameters of the algorithm are the number of Voronoï Cells and the number of clusters.</p>
<p>The paper begins with a section dedicated to presenting the context and related algorithms, followed by a detailed description of the proposed algorithm. Experiments and comparisons with reference algorithms are then conducted on both real and synthetic data.</p>
</section>
<section id="related-work" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Related Work</h1>
<p>Spectral clustering is a graph-based approach that computes the eigen-vectors of the graph’s Laplacian matrix. This technique transforms the data into a lower-dimensional space, making the clusters more discernible. A standard algorithm like k-means is then applied to these transformed features to identify the clusters <span class="citation" data-cites="von2007tutorial">(<a href="#ref-von2007tutorial" role="doc-biblioref">Von Luxburg 2007</a>)</span>. Spectral clustering enables capturing complex data structures and discerning clusters based on the connectivity of data points in a transformed space, effectively treating it as a relaxed graph cut problem.</p>
<p>Classical spectral clustering involves two phases: construction of the affinity matrix and eigen-decomposition. Constructing the affinity matrix requires <span class="math inline">O(n^2d)</span> time and <span class="math inline">O(n^2)</span> memory, while eigen-decomposition demands <span class="math inline">O(n^3)</span> time and <span class="math inline">O(n^2)</span> memory, where <span class="math inline">n</span> is the data size and <span class="math inline">d</span> is the dimension. As <span class="math inline">n</span> increases, the computational load escalates significantly <span class="citation" data-cites="von2007tutorial">(<a href="#ref-von2007tutorial" role="doc-biblioref">Von Luxburg 2007</a>)</span>.</p>
<p>To mitigate this computational burden, one common approach is to sparsify the affinity matrix and use sparse eigen-solvers, reducing memory costs but still requiring computation of all original matrix entries <span class="citation" data-cites="von2007tutorial">(<a href="#ref-von2007tutorial" role="doc-biblioref">Von Luxburg 2007</a>)</span>. Another strategy is sub-matrix construction. The Nyström method randomly selects <span class="math inline">m</span> representatives from the dataset to form an <span class="math inline">n\times m</span> affinity sub-matrix <span class="citation" data-cites="chen2010parallel">(<a href="#ref-chen2010parallel" role="doc-biblioref">Chen et al. 2010</a>)</span>. Cai et al.&nbsp;extended this with the landmark-based spectral clustering method, which uses k-means to determine <span class="math inline">m</span> cluster centers as representatives <span class="citation" data-cites="cai2014large">(<a href="#ref-cai2014large" role="doc-biblioref">Cai and Chen 2014</a>)</span>. Ultra-scalable spectral clustering (U-SPEC) employs a hybrid representative selection strategy and a fast approximation method for constructing a sparse affinity sub-matrix <span class="citation" data-cites="huang2019ultra">(<a href="#ref-huang2019ultra" role="doc-biblioref">Huang et al. 2019</a>)</span>.</p>
<p>Other approaches use the properties of the small initial clusters for the affinity computation. Clustering Based on Graph of Intensity Topology (GIT) estimates for example a global topological graph (topo-graph) between local clusters <span class="citation" data-cites="gao2021git">(<a href="#ref-gao2021git" role="doc-biblioref">Gao et al. 2021</a>)</span>. It then uses the Wasserstein Distance between predicted and prior class proportions to automatically cut noisy edges in the topo-graph and merge connected local clusters into final clusters.</p>
<p>The issue of characterizing the affinity between two clusters to create an edge weight is central to the efficiency of a spectral clustering algorithm operating from a submatrix.</p>
<p>Notice that the clustering robustness of many Spectral clustering algorithms heavily relies on the proper selection of kernel parameter, which is difficult to find without prior knowledge <span class="citation" data-cites="ng2001spectral">(<a href="#ref-ng2001spectral" role="doc-biblioref">Ng, Jordan, and Weiss 2001</a>)</span>.</p>
<!--
The approach using k-means to determine $m$ clusters and then creating a graph from these clusters is similar to certain penalized versions of Kohonen self-organizing maps, where the graph nodes are the centers of the $m$ clusters and the edge weights are related to the distance between the centroids.


$$
\text{Objective Function} = \sum_{\text{data points}} \left( \text{reconstruction error} \right) + \lambda \sum_{\text{neighbors}} (\text{weight}_{i} - \text{weight}_{j})^2
$$


Ainsi le terme de pénalité utilisé pour les carte de Kohonen pourrais être utilisé par caractériser la similiarté entre deux
-->
</section>
<section id="spectral-bridges" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Spectral Bridges</h1>
<p>The proposed algorithm uses k-means centroids for vector quantization defining Voronoï region, and a strategy is proposed to link these regions, with an “affinity” gauged in terms of minimal margin between pairs of classes. These affinities are considered as weight of edges defining a completely connected graph whose vertices are the regions. Spectral clustering on the region provide a partition of the input space. The sole parameters of the algorithm are the number of Voronoï region and the number of final cluster.</p>
<section id="sec-bridge-affinity" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="sec-bridge-affinity"><span class="header-section-number">3.1</span> Bridge affinity</h2>
<p>The basic idea involves calculating the difference in inertia achieved by projecting onto a segment connecting two centroids, rather than using the two centroids separately (see <a href="#fig-balls-bridge" class="quarto-xref">Figure&nbsp;1</a>). If the difference is small, it suggests a low density between the classes. Conversely, if this difference is large, it indicates that the two classes may reside within the same densely populated region.</p>
<div id="fig-balls-bridge" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-balls-bridge-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><embed src="figures/balls.pdf" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><embed src="figures/bridge.pdf" class="img-fluid"></p>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-balls-bridge-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Balls (left) versus Bridge (right). The inertia of each structure is the sum of the squared distances represented by grey lines.
</figcaption>
</figure>
</div>
<p>Let us consider a sample <span class="math inline">X=(\boldsymbol x_i)_{i \in \{1,\cdots,n\}}</span> of vectors <span class="math inline">\boldsymbol x_i \in \mathbb R^d</span> and a set of <span class="math inline">m</span> coding vectors <span class="math inline">(\boldsymbol \mu_k)_{k \in \{1,\cdots,m\}}</span> defining a partition <span class="math inline">P=\{\mathcal{V}_1,\cdots,\mathcal{V}_m \}</span> of <span class="math inline">\mathbb R^d</span> into <span class="math inline">m</span> Voronoï regions: <span class="math display">
\mathcal{V}_k = \left\{ \mathbf{x} \in \mathbb{R}^d \mid \|\mathbf{x} - \boldsymbol{\mu}_k\| \leq \|\mathbf{x} - \boldsymbol{\mu}_j\| \text{ for all } j \neq k \right\}.
</span></p>
<p>In the following a ball denotes the subset of <span class="math inline">X</span> in a Voronoï region. The inertia of two balls <span class="math inline">\mathcal{V}_k</span> and <span class="math inline">\mathcal{V}_l</span> is <span class="math display">
I_{kl} = \sum_{\boldsymbol x_i\in \mathcal{V}_k} \|\boldsymbol x_i - \boldsymbol \mu_k\|^2 + \sum_{\boldsymbol x_i\in \mathcal{V}_l} \|\boldsymbol x_i - \boldsymbol \mu_l\|^2.
</span> We define a bridge as a structure defined by a segment connecting two centroids <span class="math inline">\boldsymbol \mu_k</span> and <span class="math inline">\boldsymbol \mu_l</span>. The inertia of a bridge between <span class="math inline">\mathcal{V}_k</span> and <span class="math inline">\mathcal{V}_l</span> is defined as <span class="math display">
B_{kl} = \sum_{\boldsymbol x_i\in \mathcal{V}_k \cup \mathcal{V}_l} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2,
</span> where <span class="math display">
\boldsymbol p_{kl}(\boldsymbol x_i) = \boldsymbol \mu_{k} + t_i(\boldsymbol \mu_{l} - \boldsymbol \mu_{k}),
</span> with <span class="math display">
t_i = \min\left(1, \max\left(0, \frac{\langle \boldsymbol x_i - \boldsymbol \mu_k | \boldsymbol \mu_l - \boldsymbol \mu_k\rangle}{\| \boldsymbol \mu_l - \boldsymbol \mu_k \|^2}\right)\right).
</span></p>
<p>Considering two centroïds, the normalized average of the difference betweenn Bridge and balls inertia (see <a href="#gain">Appendix</a>) constitutes the basis of our affinity measure between two regions: <span class="math display">
\begin{aligned}
\frac{B_{kl}- I_{kl}}{(n_k+n_l)\|\boldsymbol \mu_k - \boldsymbol \mu_l\|^2} &amp;= \frac{\sum_{\boldsymbol{x_i} \in \mathcal V_k} \langle \boldsymbol{x_i} - \boldsymbol{\mu}_k \vert \boldsymbol{\mu}_l - \boldsymbol{\mu}_k \rangle_+^2 + \sum_{\boldsymbol{x_i} \in \mathcal V_l} \langle \boldsymbol{x_i} - \boldsymbol{\mu}_l \vert \boldsymbol{\mu}_k - \boldsymbol{\mu}_l\rangle_+^2}{(n_k+n_l)\|\boldsymbol \mu_k - \boldsymbol \mu_l\|^4},\\
&amp;= \frac{\sum_{\boldsymbol{x_i} \in \mathcal V_k \cup \mathcal V_l} \alpha_i^2}{n_k+n_l},
\end{aligned}
</span> where <span class="math display">
\alpha_i=
\begin{cases}
t_i, &amp; \text{ if } t_i\in[0,1/2],\\
1-t_i, &amp; \text{ if } t_i\in]1/2,1].
\end{cases}
</span></p>
<p>The basic intuition behind this affinity is that <span class="math inline">t_i</span> represents the relative position of the projection of <span class="math inline">\boldsymbol x_i</span> on the segment <span class="math inline">[\boldsymbol \mu_k,\boldsymbol \mu_l]</span>. <span class="math inline">\alpha_i</span> represents the relative position on the segment, with the centroid of the class to which <span class="math inline">\boldsymbol x_i</span> belongs as the reference point.</p>
<p>The boundary that separates the two clusters defined by centroids <span class="math inline">\boldsymbol \mu_k</span> and <span class="math inline">\boldsymbol \mu_l</span> is a hyperplane. This hyperplane is orthogonal to the line segment connecting the centroids and intersects this segment at its midpoint.</p>
<p>If we consider all points <span class="math inline">\boldsymbol x_i \in \mathcal V_k \cup \mathcal V_l</span> which are not projected on centroids but somewhere on the segment, the distance from a point to the hyperplane is <span class="math display">
\|\boldsymbol p_{kl}(\boldsymbol x_i) - \boldsymbol \mu_{kl}\| = (1/2-\alpha_i) \| \boldsymbol \mu_k-\boldsymbol \mu_l \|.
</span></p>
<p>This distance is similar to the concept of margin in Support Vector Machine <span class="citation" data-cites="Cortes1995">(<a href="#ref-Cortes1995" role="doc-biblioref">Cortes and Vapnik 1995</a>)</span>. When the <span class="math inline">\alpha_i</span> values are small (close to zero since <span class="math inline">\alpha_i\in [0,1/2]</span>), the margins to the hyperplane are large, indicating a low density between the classes. Conversely, if the margins are small, it suggests that the two classes may reside within the same densely populated region. Consequently, the sum of the <span class="math inline">\alpha_i</span> or <span class="math inline">\alpha_i^2</span> increases with the density of the region between the classes (See Figure <a href="#fig-interpretation" class="quarto-xref">Figure&nbsp;2</a>).</p>
<div id="fig-interpretation" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-interpretation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/svm-interpretation-3.pdf" class="img-fluid"></p>
<figcaption>Margin with close centroids</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/histo-alphai-3.pdf" class="img-fluid"></p>
<figcaption>Density of the <span class="math inline">\alpha_i</span> for close centroids</figcaption>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/svm-interpretation-10.pdf" class="img-fluid"></p>
<figcaption>Margin with well separated centroids</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/histo-alphai-10.pdf" class="img-fluid"></p>
<figcaption>Density of the <span class="math inline">\alpha_i</span> for well separated centroids</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-interpretation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Spectral Bridge affinity illustration involving two centroids. The bold black dots mark the centroids of each cluster, while the colored cells represent the final partition of data points. In subfigures (a) and (c), the length of each dotted grey segment is proportional to <span class="math inline">1/2 - \alpha_i</span>, whereas the thin black segments are proportional to <span class="math inline">\alpha_i</span>. Subfigures (b) and (d) depict the distribution of <span class="math inline">\alpha_i</span>, showing the behavior when clusters are either closely positioned (a, b) or well-separated (c, d).
</figcaption>
</figure>
</div>
<p>Note that the criterion is local and indicates the relative difference in densities between the balls and the bridge, rather than evaluating a global score for the densities of the structures.</p>
<p>Eventually, we define the bridge affinity between centroids <span class="math inline">k</span> and <span class="math inline">l</span> as the square root of the variance gain: <span class="math display">
a_{kl} =
\begin{cases}
0, &amp; \text{if } k = l, \\
\sqrt{\frac{\sum_{\boldsymbol{x_i} \in \mathcal{V}_k \cup \mathcal{V}_l} \alpha_i^2}{n_k + n_l}}, &amp; \text{otherwise}.
\end{cases}
</span></p>
<p>The inclusion of the square root redefines the variance affinity measure. Rather than using the squared Euclidean norm, the affinity is interpreted as the ratio of the standard deviation to the length of the segment connecting two centroids.</p>
<p>This concept can be generalized by introducing the <span class="math inline">p</span>-bridge affinity for any <span class="math inline">p \geq 1</span>: <span class="math display">
a_{p, kl} =
\begin{cases}
0, &amp; \text{if } k = l, \\
\left(\frac{\sum_{\boldsymbol{x_i} \in \mathcal{V}_k \cup \mathcal{V}_l} \alpha_i^p}{n_k + n_l}\right)^{1/p}, &amp; \text{otherwise}.
\end{cases}
</span></p>
<p>Both definitions are equivalent when <span class="math inline">p = 2</span>. For <span class="math inline">p = 1</span>, the affinity aligns directly with the SVM model previously discussed.</p>
<p>To allow points with large margin to dominate and make the algorithm more robust to noise and outliers we consider the following exponential transformation: <span id="eq-scaling"><span class="math display">
\tilde{a}_{kl} = g(a_{kl})=\exp(\gamma a_{kl}).
\tag{1}</span></span></p>
<p>where <span class="math inline">\gamma</span> is a scaling factor. This factor is set to ensure a large enough separation between the final coefficients. This factor is determined by the equation: <span class="math display">
\gamma = \frac{log(𝑀)}{q_{90} - q_{10}}
</span></p>
<p>where <span class="math inline">q_{10}</span> and <span class="math inline">q_{90}</span> are respectively the 10th and 90th percentiles of the original affinity matrix and <span class="math inline">M &gt; 1</span>. Thus, since the transformation is order-preserving, the 90th percentile of the newly constructed matrix is <span class="math inline">M</span> times greater than the 10th percentile. By default, <span class="math inline">M</span> is arbitrarily set to a large value of <span class="math inline">10^4</span>.</p>
<p>This regularization is crucial: with a bounded affinity metric, exponentiation enhances the separation between low and high-density regions, controlled by a scaling parameter, as in traditional spectral clustering. Redefining the metric with a square root (or power <span class="math inline">1/p</span> for the generalized affinity) helps mitigate a converse issue, where machine error can cause numerical instability when solving the Laplacian eigenproblem, especially if values become too large. Since the range of affinity values can become too wide when the initial ratio between the largest and smallest non-zero unscaled bridge affinities is high. This transformation reduces the maximum values in the affinity matrix while preserving the metric’s interpretability and distance-like properties; importantly, this adjustment is not intended for outlier detection.</p>
</section>
<section id="algorithm" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="algorithm"><span class="header-section-number">3.2</span> Algorithm</h2>
<p>The Spectral Bridges algorithm first identifies local clusters to define Voronoï regions, computes edges with affinity weights between these regions, and ultimately cuts edges between regions with low inter-region density to determine the final clusters (see <a href="#alg-spectral-bridges" class="quarto-xref">Algorithm 1</a> and <a href="#fig-steps" class="quarto-xref">Figure&nbsp;3</a>).</p>
<p>In spectral clustering, the time complexity is usually dominated by the eigen-decomposition step, which is <span class="math inline">O(n^3)</span>. However, in the case of Spectral Bridges, the k-means algorithm has a time complexity of <span class="math inline">O(n \times m \times d)</span>. For datasets with large <span class="math inline">n</span>, this can be more significant than the <span class="math inline">O(m^3)</span> time complexity of the Spectral Bridges eigen-decomposition. As for the affinity matrix construction, there are <span class="math inline">m^2</span> coefficients to be calculated. Each <span class="math inline">a_{kl}</span> coefficient requires the computation of <span class="math inline">n_k + n_l</span> dot products as well as the norm <span class="math inline">\| \boldsymbol \mu_k-\boldsymbol \mu_l \|</span>, the latter often being negligeable. Assuming that the Voronoï regions are roughly balanced in cardinality, we have <span class="math inline">n_k \approx \frac{n}{m}</span>. Since <span class="math inline">m</span> should always be less than <span class="math inline">n</span>, therefore <span class="math inline">\frac{n}{m} &gt; 1</span> and the time complexity of the affinity matrix is <span class="math inline">O(\frac{n}{m} \times m^2 \times d) = O(n \times m \times d)</span> given the acceptable range of values for <span class="math inline">m</span>. Nonetheless, this is rarely the bottleneck.</p>
<div id="alg-spectral-bridges" class="pseudocode-container quarto-float" data-caption-prefix="Algorithm" data-indent-size="1.2em" data-line-number-punc=":" data-comment-delimiter="//" data-line-number="true" data-no-end="false" data-pseudocode-number="1">
<div class="pseudocode">
\begin{algorithm} \caption{Spectral Bridges} \begin{algorithmic} \Procedure{SpectralBridges}{$X, k, m$} \Comment{$X$: input dataset, $k$: number of clusters, $m$: number of Voronoï regions} \State \textbf{Step 1: Vector Quantization} \State $\text{centroids}, \text{voronoiRegions} \gets$ \Call{KMeans}{$X, m$} \Comment{Initial centroids and Voronoi regions using k-means++} \State \textbf{Step 2: Affinity Computation} \State $A = \{g(a_{kl})\}_{kl} \gets$ \Call{Affinity}{$X, \text{centroids}, \text{voronoiRegions}$} \Comment{Compute affinity matrix $A$} \State \textbf{Step 3: Spectral Clustering} \Comment{Assign each region to a cluster} \State $\text{labels} \gets$ \Call{SpectralClustering}{$A, k$} \State \textbf{Step 4: Propagate} \Comment{Assign each data point to the cluster of its region} \State $\text{clusters} \gets$ \Call{Propagate}{$X, \text{labels}, \text{voronoiRegions}$} \State \Return $\text{clusters}$ \Comment{Return cluster labels for data points in $X$} \EndProcedure \end{algorithmic} \end{algorithm}
</div>
</div>
<div id="fig-steps" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-steps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/spectral-briges-1.pdf" class="img-fluid"></p>
<figcaption>Vector quantization</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/spectral-briges-2.pdf" class="img-fluid"></p>
<figcaption>Affinity computation</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/spectral-briges-3-4.pdf" class="img-fluid"></p>
<figcaption>Spectral clustering</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-steps-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Illustration of the Spectral Bridges algorithm with the Iris dataset (first principal plane). The bold red dots represent the centroids of the clusters, while the colored cells indicate the final partition of the data points. Vector quantization (Step 1 of <a href="#alg-spectral-bridges" class="quarto-xref">Algorithm 1</a>), Affinity computation (Step 2 of <a href="#alg-spectral-bridges" class="quarto-xref">Algorithm 1</a>), Spectral clustering and spreading (Step 3-4 of <a href="#alg-spectral-bridges" class="quarto-xref">Algorithm 1</a>).
</figcaption>
</figure>
</div>
</section>
<section id="hyperparameter-settings" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="hyperparameter-settings"><span class="header-section-number">3.3</span> Hyperparameter settings</h2>
<p>The proposed algorithm requires three input parameters: the number of clusters <span class="math inline">K</span>, the number of Voronoï regions <span class="math inline">m</span>, and a scaling parameter for the spectral clustering phase.</p>
<p>Model selection in non-parametric settings is challenging due to the absence of predefined model parameters. It relies heavily on data-driven approaches. Metrics like the Gap Statistic <span class="citation" data-cites="tibshirani2001estimating">(<a href="#ref-tibshirani2001estimating" role="doc-biblioref">Tibshirani, Walther, and Hastie 2001</a>)</span> and the Laplacian eigengap <span class="citation" data-cites="von2007tutorial">(<a href="#ref-von2007tutorial" role="doc-biblioref">Von Luxburg 2007</a>)</span> are potential tools for hyperparameter selection.</p>
<p>We propose a method for choosing the scaling parameter (see Equation <a href="#eq-scaling" class="quarto-xref">Equation&nbsp;1</a>) that yields stable results. Selecting both <span class="math inline">m</span>, the number of Voronoï regions, and <span class="math inline">K</span>, the number of clusters, is difficult. We address this by adopting a heuristic: first, choose <span class="math inline">K</span>, then determine <span class="math inline">m</span> using a modified Laplacian eigengap.</p>
<p>If <span class="math inline">K</span> represents the true number of clusters, the affinity matrix resembles a graph adjacency matrix with <span class="math inline">K</span> connected components. This configuration is characterized by an eigengap at the <span class="math inline">K</span>th eigenvalue. In Self-Tuning Spectral Clustering <span class="citation" data-cites="zelnik2004self">(<a href="#ref-zelnik2004self" role="doc-biblioref">Zelnik-Manor and Perona 2004</a>)</span>, the eigengap <span class="math inline">\lambda_{K+1} - \lambda_K</span> is used to evaluate clustering quality for <span class="math inline">K</span> clusters. Following a similar strategy, and assuming <span class="math inline">K</span> is known, the Laplacian eigengap at the <span class="math inline">K</span>th eigenvalue can select <span class="math inline">m</span>, with the scaling parameter fixed.</p>
<p>Determining the optimal value of <span class="math inline">m</span> using the eigengap is not straightforward. As the affinity matrix dimension increases, the number of eigenvalues grows, reducing gaps between them. This makes direct comparisons unreliable. To address this, we use the ratio <span class="math inline">R = (\lambda_{K+1} - \lambda_K) / \lambda_{K+1}</span>. This metric is bounded between 0 and 1 and measures the relative difference between consecutive eigenvalues. It facilitates meaningful comparisons across different values of <span class="math inline">m</span>. A value of <span class="math inline">R</span> close to 1 suggests high clustering quality, whereas lower values indicate weaker performance.</p>
<p>Using this metric, we determine a near-optimal value for <span class="math inline">m</span> by maximizing the average <span class="math inline">R</span> across possible values of <span class="math inline">m</span>. Additionally, the metric enhances robustness by running the algorithm with different random seeds and selecting the clustering result with the highest normalized eigengap.</p>
</section>
</section>
<section id="numerical-experiments" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Numerical experiments</h1>
<p>In this section, the results obtained from testing the Spectral Bridges algorithm on various datasets, both small and large scale, including real-world and well-known synthetic datasets, are presented. These experiments assess the accuracy, time and space complexity, ease of use, robustness, and adaptability of our algorithm. We compare Spectral Bridges (SB) against several state-of-the-art methods, including k-means++ (KM) <span class="citation" data-cites="macqueen1967some arthur2007kmeanspp">(<a href="#ref-macqueen1967some" role="doc-biblioref">MacQueen et al. 1967</a>; <a href="#ref-arthur2007kmeanspp" role="doc-biblioref">Arthur and Vassilvitskii 2006</a>)</span>, Expectation-Maximization (EM) <span class="citation" data-cites="dempster1977maximum">(<a href="#ref-dempster1977maximum" role="doc-biblioref">Dempster, Laird, and Rubin 1977</a>)</span>, Ward Clustering (WC) <span class="citation" data-cites="ward1963hierarchical">(<a href="#ref-ward1963hierarchical" role="doc-biblioref">Ward Jr 1963</a>)</span>, DBSCAN (DB) <span class="citation" data-cites="ester1996density">(<a href="#ref-ester1996density" role="doc-biblioref">Ester et al. 1996</a>)</span> and GIT <span class="citation" data-cites="gao2021git">(<a href="#ref-gao2021git" role="doc-biblioref">Gao et al. 2021</a>)</span>. This comparison establishes baselines across centroid-based clustering algorithms, hierarchical methods, and density-based methods.</p>
<p>The algorithms are evaluated on both raw and Principal Component Analysis processed (PCA-processed) data with varying dimensionality. For synthetic datasets, Gaussian and/or uniform noise is introduced to assess the robustness of the algorithm.</p>
<section id="datasets" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="datasets"><span class="header-section-number">4.1</span> Datasets</h2>
<section id="real-world-data" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="real-world-data"><span class="header-section-number">4.1.1</span> Real-world data</h3>
<ul>
<li><strong>MNIST</strong>: A large dataset containing 60,000 handwritten digit images in ten balanced classes, commonly used for image processing benchmarks. Each image consists of <span class="math inline">28 \times 28 = 784</span> pixels.</li>
<li><strong>UCI ML Breast Cancer Wisconsin</strong>: A dataset featuring computed attributes from digitized images of fine needle aspirates (FNA) of breast masses, used to predict whether a tumor is malignant or benign.</li>
</ul>
</section>
<section id="synthetic-data" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="synthetic-data"><span class="header-section-number">4.1.2</span> Synthetic data</h3>
<ul>
<li><strong>Impossible</strong>: A synthetic dataset designed to challenge clustering algorithms with complex patterns.</li>
<li><strong>Moons</strong>: A two-dimensional dataset with two interleaving half-circles.</li>
<li><strong>Circles</strong>: A synthetic dataset of points arranged in two non-linearly separable circles.</li>
<li><strong>Smile</strong>: A synthetic dataset with points arranged in the shape of a smiling face, used to test the separation of non-linearly separable data.</li>
</ul>
</section>
<section id="datasets-summary-class-balance" class="level3" data-number="4.1.3">
<h3 data-number="4.1.3" class="anchored" data-anchor-id="datasets-summary-class-balance"><span class="header-section-number">4.1.3</span> Datasets Summary &amp; Class Balance</h3>
<table class="caption-top table">
<caption>Datasets Summary &amp; Class Balance</caption>
<colgroup>
<col style="width: 15%">
<col style="width: 10%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 46%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Dataset</strong></th>
<th><strong>#Dims</strong></th>
<th><strong>#Samples</strong></th>
<th><strong>#Classes</strong></th>
<th><strong>Class Proportions</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MNIST</td>
<td>784</td>
<td>60000</td>
<td>10</td>
<td>9.9%, 11.2%, 9.9%, 10.3%, 9.7%, 9%, 9.9%, 10.4%, 9.7%, 9.9%</td>
</tr>
<tr class="even">
<td>Breast Cancer</td>
<td>30</td>
<td>569</td>
<td>2</td>
<td>37.3%, 62.7%</td>
</tr>
<tr class="odd">
<td>Impossible</td>
<td>2</td>
<td>3594</td>
<td>7</td>
<td>24.8%, 18.8%, 11.3%, 7.5%, 12.5%, 12.5%, 12.5%</td>
</tr>
<tr class="even">
<td>Moons</td>
<td>2</td>
<td>1000</td>
<td>2</td>
<td>50%, 50%</td>
</tr>
<tr class="odd">
<td>Circles</td>
<td>2</td>
<td>1000</td>
<td>2</td>
<td>50%, 50%</td>
</tr>
<tr class="even">
<td>Smile</td>
<td>2</td>
<td>1000</td>
<td>4</td>
<td>25%, 25%, 25%, 25%</td>
</tr>
</tbody>
</table>
<p>Class proportions are presented in ascending order starting from label <span class="math inline">0</span>.</p>
</section>
</section>
<section id="metrics" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="metrics"><span class="header-section-number">4.2</span> Metrics</h2>
<p>To evaluate the performance of the clustering algorithm, the Adjusted Rand Index (ARI) <span class="citation" data-cites="halkidi2002cluster">(<a href="#ref-halkidi2002cluster" role="doc-biblioref">Halkidi, Batistakis, and Vazirgiannis 2002</a>)</span> and Normalized Mutual Information (NMI) <span class="citation" data-cites="cover1991information">(<a href="#ref-cover1991information" role="doc-biblioref">Cover and Thomas 1991</a>)</span> are used. ARI measures the similarity between two clustering results, ranging from -0.5 to 1, with 1 indicating perfect agreement. NMI ranges from 0 to 1, with higher values indicating better clustering quality. In some tests, the variability of scores across multiple runs is also reported due to the random initialization in k-means, though k-means++ generally provides stable and reproducible results.</p>
</section>
<section id="platform" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="platform"><span class="header-section-number">4.3</span> Platform</h2>
<p>All experiments were conducted on an Archlinux machine with Linux 6.9.3 Kernel, 8GB of RAM, and an AMD Ryzen 3 7320U processor.</p>
</section>
<section id="sensitivity-to-hyperparameters" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="sensitivity-to-hyperparameters"><span class="header-section-number">4.4</span> Sensitivity to hyperparameters</h2>
<p>The hyperparameters of the Spectral Bridges algorithm were based on the size of each dataset, <span class="math inline">n</span>, and the number of clusters, <span class="math inline">K</span>.</p>
<p>To better grasp the sensitivity regarding to <span class="math inline">m</span>, the number of Voronoï cells, Spectral Bridges was run on the PCA <span class="math inline">h = 32</span> embedded MNIST dataset with varying values of <span class="math inline">m \in \{10, 120, 230, 340, 450, 560, 670, 780, 890, 1000 \}</span>. The case <span class="math inline">m = 10</span> is equivalent to the k-means++ algorithm. ARI and NMI scores are recorded over 20 consecutive iterations and subsequently plotted. As shown by <a href="#fig-m-vs-score" class="quarto-xref">Figure&nbsp;4</a>, the accuracy seems to be consistently increasing with values of <span class="math inline">m</span>, with the largest observed gap occurring between values of <span class="math inline">m = 10</span> and <span class="math inline">m = 120</span>, and flattening thereafter, indicating a tremendous improvement over the classical k-means++ framework even for empirically suboptimal hyperparameter values.</p>
<div id="fig-m-vs-score" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-m-vs-score-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/nodes_vs_score.pdf" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-m-vs-score-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: ARI and NMI scores of Spectral Bridges with varying values of <span class="math inline">m</span>.
</figcaption>
</figure>
</div>
<p>For other algorithms, such as DBSCAN, labels were used to determine the best hyperparameter values to compare our method against the “best case scenario”, thus putting the Spectral Bridges algorithm at a voluntary disadvantage.</p>
</section>
<section id="time-complexity" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="time-complexity"><span class="header-section-number">4.5</span> Time complexity</h2>
<p>To assess the algorithm’s time complexity, the average execution times over 50 runs were computed for varying numbers of Voronoï regions <span class="math inline">m</span> as well as dataset sizes. With a constant number of clusters <span class="math inline">K = 5</span> and an embedding dimension of <span class="math inline">d = 10</span>, the results (see <a href="#fig-time-complexity" class="quarto-xref">Figure&nbsp;5</a>) highlight Spectral Bridges algorihtm’s efficacy. As discussed previously, we observe a linear relationship between <span class="math inline">m</span> and the execution time because the matrix construction is highly optimized and the time taken is almost negligeable compared to that of the initial k-means++ centroids initalization.</p>
<div id="fig-time-complexity" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-time-complexity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/size_vs_time.pdf" class="img-fluid"></p>
<figcaption>Varying <span class="math inline">n</span>, fixed <span class="math inline">m = 10</span></figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/nodes_vs_time.pdf" class="img-fluid"></p>
<figcaption>Varying <span class="math inline">m</span>, fixed <span class="math inline">n = 5000</span></figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-time-complexity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Average time taken per model fit.
</figcaption>
</figure>
</div>
</section>
<section id="accuracy" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="accuracy"><span class="header-section-number">4.6</span> Accuracy</h2>
<p>The algorithm’s accuracy was first evaluated on the MNIST dataset. Metrics were collected to compare our method with k-means++, EM, and Ward clustering. Metrics were estimated by computing the empirical average over 10 consecutive runs for each method. Due to limited computational resources, we randomly selected a sample of 20,000 data points (one-third of the total) for each run, on which all algorithms were trained and tested. To ensure reproducibility, a fixed random seed was set at the beginning of all scripts. Note, however, that this does not imply centroids were initialized identically for centroid based methods, as these may vary according to the implementation of each tested algorithm.</p>
<p>Let <span class="math inline">h</span> denote the embedding dimension of the dataset. Spectral Bridges was tested both on the raw MNIST dataset without preprocessing (<span class="math inline">h = 784</span>) and after reducing its dimension using PCA to <span class="math inline">h \in \{8, 16, 32, 64\}</span> (see <a href="#fig-mnist-pca-scores" class="quarto-xref">Figure&nbsp;6</a>).</p>
<div id="fig-mnist-pca-scores" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mnist-pca-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/mnist_pca_summary.pdf" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mnist-pca-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: ARI and NMI scores of k-means++ (pink), EM (green), Ward Clustering (red), GIT (blue), and Spectral Bridges (purple) on PCA embedding and full MNIST.
</figcaption>
</figure>
</div>
<p>Furthermore, the proposed algorithm was also tested on the same MNIST dataset after reducing its dimension to <span class="math inline">h \in \{2, 4, 8, 16\}</span> using UMAP <span class="citation" data-cites="McInnes2018">(<a href="#ref-McInnes2018" role="doc-biblioref">McInnes et al. 2018</a>)</span>, a state-of-the-art non-linear dimension reduction algorithm (see <a href="#fig-mnist-umap-scores" class="quarto-xref">Figure&nbsp;7</a>). To further improve the clustering performance of Spectral Bridges, the <code>fit_select</code> method was employed. This method effectively trains the algorithm with multiple initializations and selects the one with the largest normalized eigengap (refer to the <strong>Hyperparameter settings</strong> section).</p>
<div id="fig-mnist-umap-scores" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mnist-umap-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/mnist_umap_summary.pdf" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mnist-umap-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: ARI and NMI scores of k-means++ (pink), EM (green), Ward Clustering (red), GIT (blue), Spectral Bridges (purple) on UMAP embedding
</figcaption>
</figure>
</div>
<p>Note the Spectral Bridges is substantially better than other traditional methods and shines even with quite simple dimension reduction algorithms.</p>
<p>For visualization purposes, the predicted clusters by Spectral Bridges and k-means++ were projected using UMAP to compare them against the ground truth labels and to better understand the cluster shapes (see <a href="#fig-MNIST" class="quarto-xref">Figure&nbsp;8</a>). Note this projection was not used in the experiments as an embedding, and thus does not play any role in the clustering process itself. As a matter of fact, the embedding used was obtained with Principal Componant Analysis (PCA), <span class="math inline">h = 32</span> and 250 Voronoï regions. Note that the label colors match the legend only in the case of the ground truth data. Indeed, the ordering of the labels have no significance on clustering quality.</p>
<div id="fig-MNIST" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-MNIST-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/KMumap.pdf" class="img-fluid"></p>
<figcaption>k-means++</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/SBumap.pdf" class="img-fluid"></p>
<figcaption>Spectral Bridges</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/GTumap.pdf" class="img-fluid"></p>
<figcaption>Ground Truth</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-MNIST-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: UMAP projection of predicted clusters against the ground truth labels.
</figcaption>
</figure>
</div>
<p>The Spectral Bridges algorithm was also put to the test against the same competitors using scikit-learn’s UCI Breast Cancer data. Once again, this new method performs well although the advantage is not as obvious in this case (see <a href="#fig-cancer-scores" class="quarto-xref">Figure&nbsp;9</a>). However, in none of our tests has it ranked worse than k-means++. The results are displayed as a boxplot generated from 200 iterations of each algorithm using a different seed, in order to better grasp the variability lying in the seed dependent nature of the k-means++, Expectation Maximization and Spectral Bridges algorithms.</p>
<div id="fig-cancer-scores" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cancer-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/cancer_summary.pdf" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cancer-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: ARI and NMI scores of k-means++ (blue), EM (green), Ward Clustering (red), and Spectral Bridges (purple) on the UCI Breast Cancer dataset.
</figcaption>
</figure>
</div>
<p>Since the Spectral Bridges algorithm is expected to excel at discerning complex and intricate cluster structures, an array of four toy datasets was collected, as illustrated in <a href="#fig-toy-datasets" class="quarto-xref">Figure&nbsp;10</a>.</p>
<div id="fig-toy-datasets" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-toy-datasets-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/impossible.pdf" class="img-fluid"></p>
<figcaption>Impossible</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/moons.pdf" class="img-fluid"></p>
<figcaption>Moons</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/circles.pdf" class="img-fluid"></p>
<figcaption>Circles</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/smile.pdf" class="img-fluid"></p>
<figcaption>Smile</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-toy-datasets-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Four toy datasets.
</figcaption>
</figure>
</div>
<p>Multiple algorithms, including the proposed one, were benchmarked in the exact same manner as for the UCI Breast Cancer data. The results show that the proposed method outperforms all tested algorithms (DBSCAN, k-means++, Expectation Maximization, and Ward Clustering) while requiring few hyperparameters. As previously discussed, DBSCAN’s parameters were optimized using the ground truth labels to represent a best-case scenario; however, in practical applications, suboptimal performance is more likely. Despite this optimization, the Spectral-Bridge algorithm still demonstrates superior ability to capture and represent the underlying cluster structures.</p>
<div id="fig-synthetic-scores" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-synthetic-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<embed src="figures/synthetic_summary.pdf" class="img-fluid">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-synthetic-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: ARI and NMI scores of Spectral Bridges and competitors on standard synthetic toy datasets.
</figcaption>
</figure>
</div>
<div style="page-break-after: always;"></div>
</section>
<section id="noise-robustness" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="noise-robustness"><span class="header-section-number">4.7</span> Noise robustness</h2>
<p>To evaluate the noise robustness of the algorithm, two experimental setups were devised: one involved introducing Gaussian-distributed perturbations to the data, and the other involved concatenating uniformly distributed points within a predefined rectangular region (determined by the span of the dataset) to the existing dataset. As illustrated in <a href="#fig-noise-robustness" class="quarto-xref">Figure&nbsp;12</a>, the tests demonstrate that in both scenarios, the algorithm exhibits a high degree of insensitivity to noise.</p>
<div id="fig-noise-robustness" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-noise-robustness-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/clean_impossible.pdf" class="img-fluid"></p>
<figcaption>Clean</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/uniform_noise_impossible.pdf" class="img-fluid"></p>
<figcaption>Uniform noise</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><embed src="figures/gaussian_noise_impossible.pdf" class="img-fluid"></p>
<figcaption>Gaussian noise</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-noise-robustness-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: Three representations of the algorithm’s predicted cluster centers are displayed as colored dots, with each point of the Impossible dataset shown as a small black dot. In the left graph, the dataset is unmodified. In the center graph, 250 uniformly distributed samples were added. In the right graph, Gaussian noise perturbations with <span class="math inline">\sigma = 0.1</span> were applied.
</figcaption>
</figure>
</div>
</section>
</section>
<section id="conclusive-remarks" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Conclusive remarks</h1>
<p>Spectral Bridges is an original clustering algorithm which presents a novel approach by integrating the strengths of traditional k-means and spectral clustering frameworks. This algorithm utilizes a simple affinity measure for spectral clustering, which is derived from the minimal margin between pairs of Voronoï regions.</p>
<p>The algorithm demonstrates scalability, handling large datasets efficiently through a balanced computational complexity between the k-means clustering and eigen-decomposition steps. As a non-parametric method, Spectral Bridges does not rely on strong assumptions about data distribution, enhancing its versatility across various data types. It performs exceptionally well with both synthetic and real-world data and consistently outperforms conventional clustering algorithms such as k-means, DBSCAN, and mixture models.</p>
<p>The design of Spectral Bridges ensures robustness to noise, a significant advantage in real-world applications. Additionally, the algorithm requires minimal hyperparameters, primarily the number of Voronoï regions, making it straightforward to tune and deploy.</p>
<p>Furthermore, Spectral Bridges can be kernelized, allowing it to handle data in similarity space directly, which enhances its flexibility and applicability. Overall, Spectral Bridges is a powerful, robust, and scalable clustering algorithm that offers significant improvements over traditional methods, making it an excellent tool for advanced clustering tasks across numerous domains.</p>
</section>

<section id="references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-arthur2007kmeanspp" class="csl-entry" role="listitem">
Arthur, David, and Sergei Vassilvitskii. 2006. <span>“K-Means++: The Advantages of Careful Seeding.”</span> Technical Report 2006-13. Stanford InfoLab; Stanford. <a href="http://ilpubs.stanford.edu:8090/778/">http://ilpubs.stanford.edu:8090/778/</a>.
</div>
<div id="ref-cai2014large" class="csl-entry" role="listitem">
Cai, Deng, and Xinlei Chen. 2014. <span>“Large Scale Spectral Clustering via Landmark-Based Sparse Representation.”</span> <em>IEEE Transactions on Cybernetics</em> 45 (8): 1669–80.
</div>
<div id="ref-chen2010parallel" class="csl-entry" role="listitem">
Chen, Wen-Yen, Yangqiu Song, Hongjie Bai, Chih-Jen Lin, and Edward Y Chang. 2010. <span>“Parallel Spectral Clustering in Distributed Systems.”</span> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 33 (3): 568–86.
</div>
<div id="ref-Cortes1995" class="csl-entry" role="listitem">
Cortes, Corinna, and Vladimir Vapnik. 1995. <span>“Support-Vector Networks.”</span> <em>Machine Learning</em> 20 (3): 273–97.
</div>
<div id="ref-cover1991information" class="csl-entry" role="listitem">
Cover, Thomas M, and Joy A Thomas. 1991. <span>“Information Theory and the Stock Market.”</span> <em>Elements of Information Theory. Wiley Inc., New York</em>, 543–56.
</div>
<div id="ref-dempster1977maximum" class="csl-entry" role="listitem">
Dempster, Arthur P, Nan M Laird, and Donald B Rubin. 1977. <span>“Maximum Likelihood from Incomplete Data via the EM Algorithm.”</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 39 (1): 1–22.
</div>
<div id="ref-dhillon2004kernel" class="csl-entry" role="listitem">
Dhillon, Inderjit S, Yuqiang Guan, and Brian Kulis. 2004. <span>“Kernel k-Means, Spectral Clustering and Normalized Cuts.”</span> In <em>Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, 551–56. ACM.
</div>
<div id="ref-Eisen1998" class="csl-entry" role="listitem">
Eisen, Michael B., Paul T. Spellman, Patrick O. Brown, and David Botstein. 1998. <span>“Cluster Analysis and Display of Genome-Wide Expression Patterns.”</span> <em>Proceedings of the National Academy of Sciences</em> 95 (25): 14863–68.
</div>
<div id="ref-ester1996density" class="csl-entry" role="listitem">
Ester, Martin, Hans-Peter Kriegel, Jörg Sander, Xiaowei Xu, et al. 1996. <span>“A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise.”</span> In <em>Kdd</em>, 96:226–31.
</div>
<div id="ref-gao2021git" class="csl-entry" role="listitem">
Gao, Zhangyang, Haitao Lin, Cheng Tan, Lirong Wu, Stan Li, et al. 2021. <span>“Git: Clustering Based on Graph of Intensity Topology.”</span> <em>arXiv Preprint arXiv:2110.01274</em>.
</div>
<div id="ref-govaert2003clustering" class="csl-entry" role="listitem">
Govaert, Gérard, and Mohamed Nadif. 2003. <span>“Clustering with Block Mixture Models.”</span> <em>Pattern Recognition</em> 36 (2): 463–73.
</div>
<div id="ref-halkidi2002cluster" class="csl-entry" role="listitem">
Halkidi, Maria, Yannis Batistakis, and Michalis Vazirgiannis. 2002. <span>“Cluster Validity Methods: Part i.”</span> <em>ACM SIGMOD Record</em> 31 (2): 40–45.
</div>
<div id="ref-huang2019ultra" class="csl-entry" role="listitem">
Huang, Dong, Chang-Dong Wang, Jian-Sheng Wu, Jian-Huang Lai, and Chee-Keong Kwoh. 2019. <span>“Ultra-Scalable Spectral Clustering and Ensemble Clustering.”</span> <em>IEEE Transactions on Knowledge and Data Engineering</em> 32 (6): 1212–26.
</div>
<div id="ref-jacobs1991adaptive" class="csl-entry" role="listitem">
Jacobs, Robert A, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. 1991. <span>“Adaptive Mixtures of Local Experts.”</span> <em>Neural Computation</em> 3 (1): 79–87.
</div>
<div id="ref-latouche2011" class="csl-entry" role="listitem">
Latouche, Pierre, Etienne Birmelé, and Christophe Ambroise. 2011. <span>“<span class="nocase">Overlapping stochastic block models with application to the French political blogosphere</span>.”</span> <em>The Annals of Applied Statistics</em> 5 (1): 309–36. <a href="https://doi.org/10.1214/10-AOAS382">https://doi.org/10.1214/10-AOAS382</a>.
</div>
<div id="ref-macqueen1967some" class="csl-entry" role="listitem">
MacQueen, James et al. 1967. <span>“Some Methods for Classification and Analysis of Multivariate Observations.”</span> In <em>Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability</em>, 1:281–97. Oakland, CA, USA.
</div>
<div id="ref-McInnes2018" class="csl-entry" role="listitem">
McInnes, Leland, John Healy, Nathaniel Saul, and Lukas Großberger. 2018. <span>“UMAP: Uniform Manifold Approximation and Projection.”</span> <em>Journal of Open Source Software</em> 3 (29): 861. <a href="https://doi.org/10.21105/joss.00861">https://doi.org/10.21105/joss.00861</a>.
</div>
<div id="ref-mclachlan2000finite" class="csl-entry" role="listitem">
McLachlan, Geoffrey J., and David Peel. 2000. <em>Finite Mixture Models</em>. New York: Wiley-Interscience.
</div>
<div id="ref-ng2001spectral" class="csl-entry" role="listitem">
Ng, Andrew, Michael Jordan, and Yair Weiss. 2001. <span>“On Spectral Clustering: Analysis and an Algorithm.”</span> <em>Advances in Neural Information Processing Systems</em> 14.
</div>
<div id="ref-shi2000normalized" class="csl-entry" role="listitem">
Shi, Jianbo, and Jitendra Malik. 2000. <span>“Normalized Cuts and Image Segmentation.”</span> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 22 (8): 888–905.
</div>
<div id="ref-tibshirani2001estimating" class="csl-entry" role="listitem">
Tibshirani, Robert, Guenther Walther, and Trevor Hastie. 2001. <span>“Estimating the Number of Clusters in a Data Set via the Gap Statistic.”</span> <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 63 (2): 411–23.
</div>
<div id="ref-Verhaak2010" class="csl-entry" role="listitem">
Verhaak, Roel G. W., Katherine A. Hoadley, Elizabeth Purdom, Victoria Wang, Yuexin Qi, Matthew D. Wilkerson, Charlie R. Miller, et al. 2010. <span>“Integrated Genomic Analysis Identifies Clinically Relevant Subtypes of Glioblastoma Characterized by Abnormalities in PDGFRA, IDH1, EGFR, and NF1.”</span> <em>Cancer Cell</em> 17 (1): 98–110.
</div>
<div id="ref-von2007tutorial" class="csl-entry" role="listitem">
Von Luxburg, Ulrike. 2007. <span>“A Tutorial on Spectral Clustering.”</span> <em>Statistics and Computing</em> 17: 395–416.
</div>
<div id="ref-ward1963hierarchical" class="csl-entry" role="listitem">
Ward Jr, Joe H. 1963. <span>“Hierarchical Grouping to Optimize an Objective Function.”</span> <em>Journal of the American Statistical Association</em> 58 (301): 236–44.
</div>
<div id="ref-zelnik2004self" class="csl-entry" role="listitem">
Zelnik-Manor, Lihi, and Pietro Perona. 2004. <span>“Self-Tuning Spectral Clustering.”</span> <em>Advances in Neural Information Processing Systems</em> 17.
</div>
</div>
</section>


<div id="quarto-appendix" class="default"><section id="appendix" class="level1 appendix" data-number="6"><h2 class="anchored quarto-appendix-heading"><span class="header-section-number">6</span> Appendix</h2><div class="quarto-appendix-contents">

<section id="gain" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="gain"><span class="header-section-number">6.1</span> Derivation of the bridge affinity</h2>
<p>We denote a bridge as a segment connecting two centroids <span class="math inline">\boldsymbol \mu_k</span> and <span class="math inline">\boldsymbol \mu_l</span>. The inertia of a bridge between <span class="math inline">\mathcal{V}_k</span> and <span class="math inline">\mathcal{V}_l</span> is defined as <span class="math display">
B_{kl} = \sum_{\boldsymbol x_i\in \mathcal{V}_k \cup \mathcal{V}_l} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2,
</span> where <span class="math display">
\boldsymbol p_{kl}(\boldsymbol x_i) = \boldsymbol \mu_{k} + t_i(\boldsymbol \mu_{l} - \boldsymbol \mu_{k}),
</span> with <span class="math display">
t_i = \min\left(1, \max\left(0, \frac{\langle \boldsymbol x_i - \boldsymbol \mu_k | \boldsymbol \mu_l - \boldsymbol \mu_k\rangle}{\|  \boldsymbol \mu_l - \boldsymbol \mu_k \|^2}\right)\right).
</span></p>
<p><span class="math inline">B_{kl}</span>, the bridge inertia between centroids <span class="math inline">k</span> and <span class="math inline">l</span>, can be expressed as the sum of three terms, which represents the projection onto each centroïds and onto the segment:</p>
<p><span class="math display">
\begin{aligned}
B_{kl} &amp;=&amp; \sum_{i \mid t_i=0} \|\boldsymbol x_i - \boldsymbol \mu_k\|^2  + \sum_{i \mid t_i=1} \|\boldsymbol x_i - \boldsymbol \mu_l\|^2 + \sum_{i \mid t_i\in ]0,1[} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2.
\end{aligned}
</span></p>
<p>The last term may be decomposed in two parts corresponding to the points of the two Voronoï regions which are projected on the segment:</p>
<p><span class="math display">
\begin{aligned}
\sum_{i \mid t_i\in ]0,1[} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2 &amp;=&amp; \sum_{i \mid t_i\in ]0,\frac{1}{2}[} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2 + \sum_{i \mid t_i\in [\frac{1}{2},1[} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2\\
\end{aligned}
</span> and each part further decomposed using Pythagore <span class="math display">
\begin{aligned}
\sum_{i \mid t_i\in ]0,\frac{1}{2}[} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2 &amp;=&amp; \sum_{i \mid t_i\in ]0,\frac{1}{2}[} \|\boldsymbol x_i - \boldsymbol \mu_k\|^2 - \sum_{i \mid t_i\in ]0,\frac{1}{2}[} \|\boldsymbol \mu_k - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2\\
&amp;=&amp; \sum_{i \mid t_i\in ]0,\frac{1}{2}[} \|\boldsymbol x_i - \boldsymbol \mu_k\|^2 - \sum_{i \mid t_i\in ]0,\frac{1}{2}[} \|t_i (\boldsymbol \mu_k - \boldsymbol \mu_{l})\|^2,
\end{aligned}
</span></p>
<p><span class="math display">
\begin{aligned}
\sum_{i \mid t_i\in ]\frac{1}{2},1[} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2 &amp;=&amp; \sum_{i \mid t_i\in ]0,\frac{1}{2}[} \|\boldsymbol x_i - \boldsymbol \mu_l\|^2 - \sum_{i \mid t_i\in ]0,\frac{1}{2}[} \|\boldsymbol \mu_l - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2\\
&amp;=&amp; \sum_{i \mid t_i\in ]\frac{1}{2},1[} \|\boldsymbol x_i - \boldsymbol \mu_k\|^2 - \sum_{i \mid t_i\in ]0,\frac{1}{2}[} \|(1-t_i) (\boldsymbol \mu_k - \boldsymbol \mu_{l})\|^2
\end{aligned}
</span></p>
<p>Thus <span class="math display">
\begin{aligned}
B_{kl}- I_{kl} &amp;=  \sum_{i \mid t_i\in ]0,\frac{1}{2}[} t_i^2 \|\boldsymbol \mu_k - \boldsymbol \mu_l\|^2 + \sum_{i \mid t_i\in ]\frac{1}{2},1[} (1-t_i)^2 \|\boldsymbol \mu_k - \boldsymbol \mu_l\|^2,\\
\frac{B_{kl}- I_{kl}}{\|\boldsymbol \mu_k - \boldsymbol \mu_l\|^2} &amp;= \sum_{i \mid t_i\in ]0,\frac{1}{2}[} t_i^2  + \sum_{i \mid t_i\in ]\frac{1}{2},1[} (1-t_i)^2, \\
\frac{B_{kl}- I_{kl}}{(n_k+n_l)\|\boldsymbol \mu_k - \boldsymbol \mu_l\|^2} &amp;= \frac{\sum_{\boldsymbol{x_i} \in \mathcal V_k} \langle \boldsymbol{x_i} - \boldsymbol{\mu}_k \vert \boldsymbol{\mu}_l - \boldsymbol{\mu}_k \rangle_+^2 + \sum_{\boldsymbol{x_i} \in \mathcal V_l} \langle \boldsymbol{x_i} - \boldsymbol{\mu}_l \vert \boldsymbol{\mu}_k - \boldsymbol{\mu}_l\rangle_+^2}{(n_k+n_l)\|\boldsymbol \mu_k - \boldsymbol \mu_l\|^4}.
\end{aligned}
</span></p>
</section>
<section id="code" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="code"><span class="header-section-number">6.2</span> Code</h2>
<section id="implementation" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="implementation"><span class="header-section-number">6.2.1</span> Implementation</h3>
<p>Numerical experiments have been conducted in Python. The python scripts to reproduce the simulations and figures are available at <a href="https://github.com/flheight/Spectral-Bridges" class="uri">https://github.com/flheight/Spectral-Bridges</a>. The Spectral Bridge algorithm is implemented both in</p>
<ul>
<li>Python: <a href="https://pypi.org/project/spectral-bridges" class="uri">https://pypi.org/project/spectral-bridges</a>, and</li>
<li>R: <a href="https://github.com/cambroise/spectral-bridges-Rpackage" class="uri">https://github.com/cambroise/spectral-bridges-Rpackage</a>.</li>
</ul>
</section>
<section id="affinity-matrix-computation" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2" class="anchored" data-anchor-id="affinity-matrix-computation"><span class="header-section-number">6.2.2</span> Affinity matrix computation</h3>
<p>Taking a closer look at the second step of <a href="#alg-spectral-bridges" class="quarto-xref">Algorithm 1</a>, that is the affinity matrix calculation with a <span class="math inline">O(n \times m \times d)</span> time complexity, most operations can be parallelized leaving a single loop, bundling together <span class="math inline">m^2</span> dot products into only <span class="math inline">m</span> matrix multiplications, thus allowing for an efficient construction in both high and low level programming languages. Though the complexity of the algorithm remains unchanged, libraries such as Basic Linear Algebra Subprograms can render the calculations orders of magnitude faster. Moreover, the symmetrical nature of the bridge affinity can be used to effectively halve the computation time.</p>
<p>The calculation of the affinity matrix is highlighted by the Python code <a href="#lst-code-affinity" class="quarto-xref">Listing&nbsp;1</a>. Though it could be even more optimized, the following code snippet is approximately 200 times faster than a naive implementation on a small dataset comprised of <span class="math inline">n = 3594</span>, <span class="math inline">d = 2</span> points, and a value of <span class="math inline">m = 250</span>.</p>
<p>Notice that the Python code is significantly faster than the R code.</p>
<div class="cell" data-python.reticulate="false">
<div id="lst-code-affinity" class="python cell-code listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-code-affinity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;1: Python code for affinity matrix computation
</figcaption>
<div aria-describedby="lst-code-affinity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="sourceCode cell-code" id="lst-code-affinity"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="lst-code-affinity-1"><a href="#lst-code-affinity-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Initialize the matrix as empty</span></span>
<span id="lst-code-affinity-2"><a href="#lst-code-affinity-2" aria-hidden="true" tabindex="-1"></a>affinity <span class="op">=</span> np.empty((<span class="va">self</span>.n_nodes, <span class="va">self</span>.n_nodes))</span>
<span id="lst-code-affinity-3"><a href="#lst-code-affinity-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-code-affinity-4"><a href="#lst-code-affinity-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Center each region</span></span>
<span id="lst-code-affinity-5"><a href="#lst-code-affinity-5" aria-hidden="true" tabindex="-1"></a>X_centered <span class="op">=</span> [</span>
<span id="lst-code-affinity-6"><a href="#lst-code-affinity-6" aria-hidden="true" tabindex="-1"></a>    np.array(</span>
<span id="lst-code-affinity-7"><a href="#lst-code-affinity-7" aria-hidden="true" tabindex="-1"></a>        X[kmeans.labels_ <span class="op">==</span> i] <span class="op">-</span> kmeans.cluster_centers_[i],</span>
<span id="lst-code-affinity-8"><a href="#lst-code-affinity-8" aria-hidden="true" tabindex="-1"></a>        dtype<span class="op">=</span>np.float32,</span>
<span id="lst-code-affinity-9"><a href="#lst-code-affinity-9" aria-hidden="true" tabindex="-1"></a>        order<span class="op">=</span><span class="st">"F"</span>,</span>
<span id="lst-code-affinity-10"><a href="#lst-code-affinity-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="lst-code-affinity-11"><a href="#lst-code-affinity-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_nodes)</span>
<span id="lst-code-affinity-12"><a href="#lst-code-affinity-12" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="lst-code-affinity-13"><a href="#lst-code-affinity-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-code-affinity-14"><a href="#lst-code-affinity-14" aria-hidden="true" tabindex="-1"></a><span class="co">#Cardinal calculation</span></span>
<span id="lst-code-affinity-15"><a href="#lst-code-affinity-15" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> np.array([X_centered[i].shape[<span class="dv">0</span>] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_nodes)])</span>
<span id="lst-code-affinity-16"><a href="#lst-code-affinity-16" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> counts[<span class="va">None</span>, :] <span class="op">+</span> counts[:, <span class="va">None</span>]</span>
<span id="lst-code-affinity-17"><a href="#lst-code-affinity-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-code-affinity-18"><a href="#lst-code-affinity-18" aria-hidden="true" tabindex="-1"></a><span class="co">#Calculate the affinity</span></span>
<span id="lst-code-affinity-19"><a href="#lst-code-affinity-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_nodes):</span>
<span id="lst-code-affinity-20"><a href="#lst-code-affinity-20" aria-hidden="true" tabindex="-1"></a>    segments <span class="op">=</span> np.asfortranarray(</span>
<span id="lst-code-affinity-21"><a href="#lst-code-affinity-21" aria-hidden="true" tabindex="-1"></a>        kmeans.cluster_centers_ <span class="op">-</span> kmeans.cluster_centers_[i]</span>
<span id="lst-code-affinity-22"><a href="#lst-code-affinity-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="lst-code-affinity-23"><a href="#lst-code-affinity-23" aria-hidden="true" tabindex="-1"></a>    dists <span class="op">=</span> np.einsum(<span class="st">"ij,ij-&gt;i"</span>, segments, segments)</span>
<span id="lst-code-affinity-24"><a href="#lst-code-affinity-24" aria-hidden="true" tabindex="-1"></a>    dists[i] <span class="op">=</span> <span class="dv">1</span></span>
<span id="lst-code-affinity-25"><a href="#lst-code-affinity-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-code-affinity-26"><a href="#lst-code-affinity-26" aria-hidden="true" tabindex="-1"></a>    projs <span class="op">=</span> sgemm(<span class="fl">1.0</span>, X_centered[i], segments, trans_b<span class="op">=</span><span class="va">True</span>)</span>
<span id="lst-code-affinity-27"><a href="#lst-code-affinity-27" aria-hidden="true" tabindex="-1"></a>    np.clip(projs <span class="op">/</span> dists, <span class="dv">0</span>, <span class="va">None</span>, out<span class="op">=</span>projs)</span>
<span id="lst-code-affinity-28"><a href="#lst-code-affinity-28" aria-hidden="true" tabindex="-1"></a>    projs <span class="op">=</span> np.power(projs, <span class="va">self</span>.p)</span>
<span id="lst-code-affinity-29"><a href="#lst-code-affinity-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-code-affinity-30"><a href="#lst-code-affinity-30" aria-hidden="true" tabindex="-1"></a>    affinity[i] <span class="op">=</span> projs.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="lst-code-affinity-31"><a href="#lst-code-affinity-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-code-affinity-32"><a href="#lst-code-affinity-32" aria-hidden="true" tabindex="-1"></a>affinity <span class="op">=</span> np.power((affinity <span class="op">+</span> affinity.T) <span class="op">/</span> counts, <span class="dv">1</span> <span class="op">/</span> <span class="va">self</span>.p)</span>
<span id="lst-code-affinity-33"><a href="#lst-code-affinity-33" aria-hidden="true" tabindex="-1"></a>affinity <span class="op">-=</span> <span class="fl">0.5</span> <span class="op">*</span> affinity.<span class="bu">max</span>()</span>
<span id="lst-code-affinity-34"><a href="#lst-code-affinity-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-code-affinity-35"><a href="#lst-code-affinity-35" aria-hidden="true" tabindex="-1"></a><span class="co">#Scale and exponentiate</span></span>
<span id="lst-code-affinity-36"><a href="#lst-code-affinity-36" aria-hidden="true" tabindex="-1"></a>q10, q90 <span class="op">=</span> np.quantile(affinity, [<span class="fl">0.1</span>, <span class="fl">0.9</span>])</span>
<span id="lst-code-affinity-37"><a href="#lst-code-affinity-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="lst-code-affinity-38"><a href="#lst-code-affinity-38" aria-hidden="true" tabindex="-1"></a>gamma <span class="op">=</span> np.log(<span class="va">self</span>.M) <span class="op">/</span> (q90 <span class="op">-</span> q10)</span>
<span id="lst-code-affinity-39"><a href="#lst-code-affinity-39" aria-hidden="true" tabindex="-1"></a>affinity <span class="op">=</span> np.exp(gamma <span class="op">*</span> affinity)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</figure>
</div>
</div>
<div style="page-break-after: always;"></div>
</section>
</section>
</div></section><section id="session-information" class="level1 appendix unnumbered"><h2 class="anchored quarto-appendix-heading">Session information</h2><div class="quarto-appendix-contents">

<div class="cell">
<details class="code-fold">
<summary>Hide/Show the code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>R version 4.4.1 (2024-06-14 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 11 x64 (build 22631)

Matrix products: default


locale:
[1] LC_COLLATE=French_France.utf8  LC_CTYPE=French_France.utf8   
[3] LC_MONETARY=French_France.utf8 LC_NUMERIC=C                  
[5] LC_TIME=French_France.utf8    

time zone: Europe/Paris
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
 [1] htmlwidgets_1.6.4 compiler_4.4.1    fastmap_1.2.0     cli_3.6.3        
 [5] tools_4.4.1       htmltools_0.5.8.1 rstudioapi_0.16.0 yaml_2.3.8       
 [9] rmarkdown_2.27    knitr_1.47        jsonlite_1.8.8    xfun_0.45        
[13] digest_0.6.36     rlang_1.1.4       evaluate_0.24.0  </code></pre>
</div>
</div>
<!-- -->

</div></section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@article{laplante2025,
  author = {Laplante, Félix and Ambroise, Christophe},
  title = {Spectral {Bridges}},
  journal = {Computo},
  date = {2025-07-06},
  url = {https://github.com/cambroise/spectral-bridges-computo},
  doi = {10.xxxx/xxx-xxx},
  issn = {2824-7795},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-laplante2025" class="csl-entry quarto-appendix-citeas" role="listitem">
Laplante, Félix, and Christophe Ambroise. 2025. <span>“Spectral
Bridges.”</span> <em>Computo</em>, July. <a href="https://doi.org/10.xxxx/xxx-xxx">https://doi.org/10.xxxx/xxx-xxx</a>.
</div></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb3" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Spectral Bridges"</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Scalable Spectral Clustering Based on Vector Quantization"</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 19/06/2024</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="an">date-modified:</span><span class="co"> last-modified</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Félix Laplante</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">    email: flheight0@gmail.com</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations:</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">      - Université de Paris Saclay</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Christophe Ambroise</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co">    corresponding: true</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">    email: christophe.ambroise@univ-evry.fr</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co">    url: https://computo.sfds.asso.fr</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co">    orcid: 0000-0002-8148-0346</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations:</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co">      - name: Université Paris-Saclay, CNRS, Univ Evry, </span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co">        department: Laboratoire de Mathématiques et Modélisation d'Evry</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co">        address: 23 boulevard de France</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co">        city: Evry-Courcouronnes</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co">        country: France</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> |</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co">  This document provides a template based on the quarto system for contributions to Computo. The github repository in itself provides a specific quarto extension useful for authors (and editors!).</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="an">keywords:</span><span class="co"> [spectral clustering, vector quantization, scalable, non-parametric]</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="an">doi:</span><span class="co"> 10.xxxx/xxx-xxx</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="an">citation:</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="co">  type: article-journal</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="co">  container-title: "Computo"</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a><span class="co">  doi: "10.xxxx/xxx-xxx"</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="co">  url: "https://github.com/cambroise/spectral-bridges-computo"</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co">  issn: "2824-7795"</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="an">google-scholar:</span><span class="co"> true</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="an">github-user:</span><span class="co"> cambroise</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a><span class="an">repo:</span><span class="co"> "spectral-bridges"</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a><span class="an">draft:</span><span class="co"> true # set to false once the build is running</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="an">published:</span><span class="co"> false # will be set to true once accepted</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a><span class="co">  computo-html: default </span></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a><span class="co">  computo-pdf:  default</span></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span><span class="co"> </span></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a><span class="co">  markdown: </span></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a><span class="co">    wrap: 72</span></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a><span class="fu"># Abstract</span></span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>In this paper, Spectral Bridges, a novel clustering algorithm, is introduced. This algorithm builds upon the traditional k-means and spectral clustering frameworks by subdividing data into small Voronoï regions, which are subsequently merged according to a connectivity measure. Drawing inspiration from Support Vector Machine's margin concept, a non-parametric clustering approach is proposed, building an affinity margin between each pair of Voronoï regions. This approach delineates intricate, non-convex cluster structures and is robust to hyperparameter choice.</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>The numerical experiments underscore Spectral Bridges as a fast, robust, and versatile tool for  clustering tasks spanning diverse domains. Its efficacy extends to large-scale scenarios encompassing both real-world and synthetic datasets. </span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>The Spectral Bridge algorithm is implemented both in Python (<span class="ot">&lt;https://pypi.org/project/spectral-bridges&gt;</span>) and R <span class="ot">&lt;https://github.com/cambroise/spectral-bridges-Rpackage&gt;</span>).</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction</span></span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>Clustering is a fundamental technique for exploratory data analysis, organizing a set of objects into distinct homogeneous groups known as clusters. It is extensively utilized across various fields, such as biology for gene expression analysis <span class="co">[</span><span class="ot">@Eisen1998</span><span class="co">]</span>, social sciences for community detection in social networks <span class="co">[</span><span class="ot">@latouche2011</span><span class="co">]</span>, and psychology for identifying behavioral patterns. Clustering is often employed alongside supervised learning as a pre-processing step, helping to structure and simplify data, thus enhancing the performance and interpretability of subsequent predictive models <span class="co">[</span><span class="ot">@Verhaak2010</span><span class="co">]</span>. Additionally, clustering can be integrated into supervised learning algorithms, such as mixture of experts <span class="co">[</span><span class="ot">@jacobs1991adaptive</span><span class="co">]</span>, as part of a multi-objective strategy.</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>There are various approaches to clustering, and the quality of the results is largely determined by how the similarity between objects is defined, either through a similarity measure or a distance metric. Clustering techniques originate from diverse fields of research, such as genetics, psychometry, statistics, and computer science. Some methods are entirely heuristic, while others aim to optimize specific criteria and can be related to statistical models. </span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--This diversity reflects the multidisciplinary nature of clustering, incorporating insights and methodologies from multiple scientific disciplines.</span></span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a><span class="co">--&gt;</span></span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a>Density-based methods identify regions within the data with a high concentration of points, corresponding to the modes of the joint density. A notable non-parametric example of this approach is DBSCAN <span class="co">[</span><span class="ot">@ester1996density</span><span class="co">]</span>. In contrast, model-based clustering, such as Gaussian mixture models, represents a parametric approach to density-based methods. Model-based clustering assumes that the data is generated from a mixture of underlying probability distributions, typically Gaussian distributions. Each cluster is viewed as a component of this mixture model, and the Expectation-Maximization (EM) algorithm is often used to estimate the parameters. This approach provides a probabilistic framework for clustering, allowing for the incorporation of prior knowledge and the ability to handle more complex cluster shapes and distributions <span class="co">[</span><span class="ot">@mclachlan2000finite</span><span class="co">]</span>.</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>Geometric approaches, such as k-means <span class="co">[</span><span class="ot">@macqueen1967some</span><span class="co">]</span>, are distance-based methods that aim to partition data by optimizing a criterion reflecting group homogeneity. The k-means++ algorithm <span class="co">[</span><span class="ot">@arthur2007kmeanspp</span><span class="co">]</span> enhances this approach by providing faster and more reliable results. However, a key limitation of these methods is the assumption of linear boundaries between clusters, implying that clusters are convex. To address non-convex clusters, the kernel trick can be applied, allowing for a more flexible k-means algorithm. This approach is comparable to spectral clustering in handling complex cluster boundaries <span class="co">[</span><span class="ot">@dhillon2004kernel</span><span class="co">]</span>. The k-means algorithm can also be interpreted within the framework of model-based clustering under specific assumptions <span class="co">[</span><span class="ot">@govaert2003clustering</span><span class="co">]</span>, revealing that it is essentially a special case of the more general Gaussian mixture models, where clusters are assumed to be spherical Gaussian distributions with equal variance.</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a>Graph-based methods represent data as a graph, with vertices symbolizing data points and edges weighted to indicate the affinity between these points. Spectral clustering can be seen as a relaxed version of the graph cut algorithm <span class="co">[</span><span class="ot">@shi2000normalized</span><span class="co">]</span>. However, traditional spectral clustering faces significant limitations due to its high time and space complexity, greatly hindering its applicability to large-scale problems <span class="co">[</span><span class="ot">@von2007tutorial</span><span class="co">]</span>.</span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>The method we propose aims to find non-convex clusters in large datasets, without relying on a parametric model, by using spectral clustering based on an affinity that characterizes the local density of the data. The algorithm described in this paper draws from numerous clustering approaches. The initial intuition is to detect high-density areas. To this end, vector quantization is used to divide the space into a Voronoï tessellation. An original geometric criterion is then employed to detect pairs of Voronoï regions that are either distant from each other or separated by a low-density boundary. Finally, this affinity measure is considered as the weight of an edge in a complete graph connecting the centroids of the tessellation, and a spectral clustering algorithm is used to find a partition of this graph. The only parameters of the algorithm are the number of Voronoï Cells and the number of clusters.   </span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>The paper begins with a section dedicated to presenting the context and related algorithms, followed by a detailed description of the proposed algorithm. Experiments and comparisons with reference algorithms are then conducted on both real and synthetic data.</span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a><span class="fu"># Related Work</span></span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a>Spectral clustering is a graph-based approach that computes the eigen-vectors of the graph's Laplacian matrix. This technique transforms the data into a lower-dimensional space, making the clusters more discernible. A standard algorithm like k-means is then applied to these transformed features to identify the clusters <span class="co">[</span><span class="ot">@von2007tutorial</span><span class="co">]</span>. Spectral clustering enables capturing complex data structures and discerning clusters based on the connectivity of data points in a transformed space, effectively treating it as a relaxed graph cut problem.</span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a>Classical spectral clustering involves two phases: construction of the affinity matrix and eigen-decomposition. Constructing the affinity matrix requires $O(n^2d)$ time  and $O(n^2)$ memory, while eigen-decomposition demands $O(n^3)$ time and $O(n^2)$ memory, where $n$ is the data size and $d$ is the dimension. As $n$ increases, the computational load escalates significantly <span class="co">[</span><span class="ot">@von2007tutorial</span><span class="co">]</span>.</span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a>To mitigate this computational burden, one common approach is to sparsify the affinity matrix and use sparse eigen-solvers, reducing memory costs but still requiring computation of all original matrix entries <span class="co">[</span><span class="ot">@von2007tutorial</span><span class="co">]</span>. Another strategy is sub-matrix construction. The Nyström method randomly selects $m$ representatives from the dataset to form an $n\times m$ affinity sub-matrix <span class="co">[</span><span class="ot">@chen2010parallel</span><span class="co">]</span>. Cai et al. extended this with the landmark-based spectral clustering method, which uses k-means to determine $m$ cluster centers as representatives <span class="co">[</span><span class="ot">@cai2014large</span><span class="co">]</span>. Ultra-scalable spectral clustering (U-SPEC) employs a hybrid representative selection strategy and a fast approximation method for constructing a sparse affinity sub-matrix <span class="co">[</span><span class="ot">@huang2019ultra</span><span class="co">]</span>. </span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true" tabindex="-1"></a>Other approaches use the properties of the small initial clusters for the affinity computation. Clustering Based on Graph of Intensity Topology (GIT) estimates for example a global topological graph (topo-graph) between local clusters <span class="co">[</span><span class="ot">@gao2021git</span><span class="co">]</span>. It then uses the Wasserstein Distance between predicted and prior class proportions to automatically cut noisy edges in the topo-graph and merge connected local clusters into final clusters. </span>
<span id="cb3-84"><a href="#cb3-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-85"><a href="#cb3-85" aria-hidden="true" tabindex="-1"></a>The issue of characterizing the affinity between two clusters to create an edge weight is central to the efficiency of a spectral clustering algorithm operating from a submatrix.</span>
<span id="cb3-86"><a href="#cb3-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-87"><a href="#cb3-87" aria-hidden="true" tabindex="-1"></a>Notice that the clustering robustness of many Spectral clustering algorithms heavily relies on the proper selection of kernel parameter, which is difficult to find without prior knowledge <span class="co">[</span><span class="ot">@ng2001spectral</span><span class="co">]</span>.</span>
<span id="cb3-88"><a href="#cb3-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-89"><a href="#cb3-89" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--</span></span>
<span id="cb3-90"><a href="#cb3-90" aria-hidden="true" tabindex="-1"></a><span class="co">The approach using k-means to determine $m$ clusters and then creating a graph from these clusters is similar to certain penalized versions of Kohonen self-organizing maps, where the graph nodes are the centers of the $m$ clusters and the edge weights are related to the distance between the centroids.</span></span>
<span id="cb3-91"><a href="#cb3-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-92"><a href="#cb3-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-93"><a href="#cb3-93" aria-hidden="true" tabindex="-1"></a><span class="co">$$</span></span>
<span id="cb3-94"><a href="#cb3-94" aria-hidden="true" tabindex="-1"></a><span class="co">\text{Objective Function} = \sum_{\text{data points}} \left( \text{reconstruction error} \right) + \lambda \sum_{\text{neighbors}} (\text{weight}_{i} - \text{weight}_{j})^2</span></span>
<span id="cb3-95"><a href="#cb3-95" aria-hidden="true" tabindex="-1"></a><span class="co">$$</span></span>
<span id="cb3-96"><a href="#cb3-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-97"><a href="#cb3-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-98"><a href="#cb3-98" aria-hidden="true" tabindex="-1"></a><span class="co">Ainsi le terme de pénalité utilisé pour les carte de Kohonen pourrais être utilisé par caractériser la similiarté entre deux</span></span>
<span id="cb3-99"><a href="#cb3-99" aria-hidden="true" tabindex="-1"></a><span class="co">--&gt;</span></span>
<span id="cb3-100"><a href="#cb3-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-101"><a href="#cb3-101" aria-hidden="true" tabindex="-1"></a><span class="fu"># Spectral Bridges</span></span>
<span id="cb3-102"><a href="#cb3-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-103"><a href="#cb3-103" aria-hidden="true" tabindex="-1"></a>The proposed algorithm uses k-means centroids for vector quantization defining Voronoï region, and a strategy is proposed to link these regions, with an "affinity" gauged in terms of minimal margin between pairs of classes. These affinities are considered as weight of edges defining a completely connected graph whose vertices are the regions. Spectral clustering on the region provide a partition of the input space. The sole parameters of the algorithm are the number of Voronoï region and the number of final cluster. </span>
<span id="cb3-104"><a href="#cb3-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-105"><a href="#cb3-105" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bridge affinity {#sec-bridge-affinity}</span></span>
<span id="cb3-106"><a href="#cb3-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-107"><a href="#cb3-107" aria-hidden="true" tabindex="-1"></a>The basic idea involves calculating the difference in inertia achieved by projecting onto a segment connecting two centroids, rather than using the two centroids separately (see @fig-balls-bridge). If the difference is small, it suggests a low density between the classes. Conversely, if this difference is large, it indicates that the two classes may reside within the same densely populated region.</span>
<span id="cb3-108"><a href="#cb3-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-109"><a href="#cb3-109" aria-hidden="true" tabindex="-1"></a>::: {#fig-balls-bridge layout-ncol=2}</span>
<span id="cb3-110"><a href="#cb3-110" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/balls.pdf)</span>{width=50%}</span>
<span id="cb3-111"><a href="#cb3-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-112"><a href="#cb3-112" aria-hidden="true" tabindex="-1"></a><span class="al">![](figures/bridge.pdf)</span>{width=50%}</span>
<span id="cb3-113"><a href="#cb3-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-114"><a href="#cb3-114" aria-hidden="true" tabindex="-1"></a>Balls (left) versus Bridge (right). The inertia of each structure is the sum of the squared distances represented by grey lines.</span>
<span id="cb3-115"><a href="#cb3-115" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-116"><a href="#cb3-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-117"><a href="#cb3-117" aria-hidden="true" tabindex="-1"></a>Let us consider a sample $X=(\boldsymbol x_i)_{i \in \{1,\cdots,n\}}$ of vectors $\boldsymbol x_i \in \mathbb R^d$ and a set of $m$ coding vectors $(\boldsymbol \mu_k)_{k \in <span class="sc">\{</span>1,\cdots,m<span class="sc">\}</span>}$ defining a partition $P=<span class="sc">\{</span>\mathcal{V}_1,\cdots,\mathcal{V}_m <span class="sc">\}</span>$ of $\mathbb R^d$ into $m$ Voronoï regions:</span>
<span id="cb3-118"><a href="#cb3-118" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-119"><a href="#cb3-119" aria-hidden="true" tabindex="-1"></a>\mathcal{V}_k = \left<span class="sc">\{</span> \mathbf{x} \in \mathbb{R}^d \mid \|\mathbf{x} - \boldsymbol{\mu}_k\| \leq \|\mathbf{x} - \boldsymbol{\mu}_j\| \text{ for all } j \neq k \right<span class="sc">\}</span>.</span>
<span id="cb3-120"><a href="#cb3-120" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-121"><a href="#cb3-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-122"><a href="#cb3-122" aria-hidden="true" tabindex="-1"></a>In the following a ball denotes the subset of $X$ in a Voronoï region. The inertia of two balls $\mathcal{V}_k$ and $\mathcal{V}_l$ is </span>
<span id="cb3-123"><a href="#cb3-123" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-124"><a href="#cb3-124" aria-hidden="true" tabindex="-1"></a>I_{kl} = \sum_{\boldsymbol x_i\in \mathcal{V}_k} \|\boldsymbol x_i - \boldsymbol \mu_k\|^2 + \sum_{\boldsymbol x_i\in \mathcal{V}_l} \|\boldsymbol x_i - \boldsymbol \mu_l\|^2.</span>
<span id="cb3-125"><a href="#cb3-125" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb3-126"><a href="#cb3-126" aria-hidden="true" tabindex="-1"></a>We define a bridge as a structure defined by a segment connecting two centroids $\boldsymbol \mu_k$ and $\boldsymbol \mu_l$. The inertia of a bridge between $\mathcal{V}_k$ and $\mathcal{V}_l$ is defined as </span>
<span id="cb3-127"><a href="#cb3-127" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-128"><a href="#cb3-128" aria-hidden="true" tabindex="-1"></a>B_{kl} = \sum_{\boldsymbol x_i\in \mathcal{V}_k \cup \mathcal{V}_l} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2,</span>
<span id="cb3-129"><a href="#cb3-129" aria-hidden="true" tabindex="-1"></a>$$ where </span>
<span id="cb3-130"><a href="#cb3-130" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-131"><a href="#cb3-131" aria-hidden="true" tabindex="-1"></a>\boldsymbol p_{kl}(\boldsymbol x_i) = \boldsymbol \mu_{k} + t_i(\boldsymbol \mu_{l} - \boldsymbol \mu_{k}),</span>
<span id="cb3-132"><a href="#cb3-132" aria-hidden="true" tabindex="-1"></a>$$ with $$</span>
<span id="cb3-133"><a href="#cb3-133" aria-hidden="true" tabindex="-1"></a>t_i = \min\left(1, \max\left(0, \frac{\langle \boldsymbol x_i - \boldsymbol \mu_k | \boldsymbol \mu_l - \boldsymbol \mu_k\rangle}{\| \boldsymbol \mu_l - \boldsymbol \mu_k \|^2}\right)\right). </span>
<span id="cb3-134"><a href="#cb3-134" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb3-135"><a href="#cb3-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-136"><a href="#cb3-136" aria-hidden="true" tabindex="-1"></a>Considering two centroïds, the normalized average of the difference betweenn Bridge and balls inertia (see <span class="co">[</span><span class="ot">Appendix</span><span class="co">](#gain)</span>) constitutes the basis of our affinity measure between two regions:</span>
<span id="cb3-137"><a href="#cb3-137" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-138"><a href="#cb3-138" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb3-139"><a href="#cb3-139" aria-hidden="true" tabindex="-1"></a>\frac{B_{kl}- I_{kl}}{(n_k+n_l)\|\boldsymbol \mu_k - \boldsymbol \mu_l\|^2} &amp;= \frac{\sum_{\boldsymbol{x_i} \in \mathcal V_k} \langle \boldsymbol{x_i} - \boldsymbol{\mu}_k \vert \boldsymbol{\mu}_l - \boldsymbol{\mu}_k \rangle_+^2 + \sum_{\boldsymbol{x_i} \in \mathcal V_l} \langle \boldsymbol{x_i} - \boldsymbol{\mu}_l \vert \boldsymbol{\mu}_k - \boldsymbol{\mu}_l\rangle_+^2}{(n_k+n_l)\|\boldsymbol \mu_k - \boldsymbol \mu_l\|^4},<span class="sc">\\</span></span>
<span id="cb3-140"><a href="#cb3-140" aria-hidden="true" tabindex="-1"></a>&amp;= \frac{\sum_{\boldsymbol{x_i} \in \mathcal V_k \cup \mathcal V_l} \alpha_i^2}{n_k+n_l},</span>
<span id="cb3-141"><a href="#cb3-141" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb3-142"><a href="#cb3-142" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-143"><a href="#cb3-143" aria-hidden="true" tabindex="-1"></a>where </span>
<span id="cb3-144"><a href="#cb3-144" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-145"><a href="#cb3-145" aria-hidden="true" tabindex="-1"></a>\alpha_i=</span>
<span id="cb3-146"><a href="#cb3-146" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb3-147"><a href="#cb3-147" aria-hidden="true" tabindex="-1"></a>t_i, &amp; \text{ if } t_i\in<span class="co">[</span><span class="ot">0,1/2</span><span class="co">]</span>,<span class="sc">\\</span></span>
<span id="cb3-148"><a href="#cb3-148" aria-hidden="true" tabindex="-1"></a>1-t_i, &amp; \text{ if } t_i\in]1/2,1].</span>
<span id="cb3-149"><a href="#cb3-149" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb3-150"><a href="#cb3-150" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb3-151"><a href="#cb3-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-152"><a href="#cb3-152" aria-hidden="true" tabindex="-1"></a>The basic intuition behind this affinity is that $t_i$ represents the</span>
<span id="cb3-153"><a href="#cb3-153" aria-hidden="true" tabindex="-1"></a>relative position of the projection of $\boldsymbol x_i$ on the segment</span>
<span id="cb3-154"><a href="#cb3-154" aria-hidden="true" tabindex="-1"></a>$<span class="co">[</span><span class="ot">\boldsymbol \mu_k,\boldsymbol \mu_l</span><span class="co">]</span>$. $\alpha_i$ represents the relative position on the segment, </span>
<span id="cb3-155"><a href="#cb3-155" aria-hidden="true" tabindex="-1"></a>with the centroid of the class to which $\boldsymbol x_i$ belongs as the reference point.</span>
<span id="cb3-156"><a href="#cb3-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-157"><a href="#cb3-157" aria-hidden="true" tabindex="-1"></a>The boundary that separates the two clusters defined by centroids</span>
<span id="cb3-158"><a href="#cb3-158" aria-hidden="true" tabindex="-1"></a>$\boldsymbol \mu_k$ and $\boldsymbol \mu_l$ is a hyperplane. This</span>
<span id="cb3-159"><a href="#cb3-159" aria-hidden="true" tabindex="-1"></a>hyperplane is orthogonal to the line segment connecting the centroids</span>
<span id="cb3-160"><a href="#cb3-160" aria-hidden="true" tabindex="-1"></a>and intersects this segment at its midpoint.</span>
<span id="cb3-161"><a href="#cb3-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-162"><a href="#cb3-162" aria-hidden="true" tabindex="-1"></a>If we consider all points $\boldsymbol x_i \in \mathcal V_k \cup \mathcal V_l$ which are not projected on centroids but somewhere on the segment, the distance from</span>
<span id="cb3-163"><a href="#cb3-163" aria-hidden="true" tabindex="-1"></a>a point to the hyperplane is </span>
<span id="cb3-164"><a href="#cb3-164" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-165"><a href="#cb3-165" aria-hidden="true" tabindex="-1"></a>\|\boldsymbol p_{kl}(\boldsymbol x_i) - \boldsymbol \mu_{kl}\| = (1/2-\alpha_i) \| \boldsymbol \mu_k-\boldsymbol \mu_l \|.</span>
<span id="cb3-166"><a href="#cb3-166" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-167"><a href="#cb3-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-168"><a href="#cb3-168" aria-hidden="true" tabindex="-1"></a>This distance is similar to the concept of margin in Support Vector Machine <span class="co">[</span><span class="ot">@Cortes1995</span><span class="co">]</span>. When the $\alpha_i$ values are small (close to zero since $\alpha_i\in <span class="co">[</span><span class="ot">0,1/2</span><span class="co">]</span>$), the margins to the hyperplane are large, indicating a low density between the classes. Conversely, if</span>
<span id="cb3-169"><a href="#cb3-169" aria-hidden="true" tabindex="-1"></a>the margins are small, it suggests that the two classes may reside</span>
<span id="cb3-170"><a href="#cb3-170" aria-hidden="true" tabindex="-1"></a>within the same densely populated region. Consequently, the sum of the</span>
<span id="cb3-171"><a href="#cb3-171" aria-hidden="true" tabindex="-1"></a>$\alpha_i$ or $\alpha_i^2$ increases with the density of the region</span>
<span id="cb3-172"><a href="#cb3-172" aria-hidden="true" tabindex="-1"></a>between the classes (See Figure @fig-interpretation). </span>
<span id="cb3-173"><a href="#cb3-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-174"><a href="#cb3-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-175"><a href="#cb3-175" aria-hidden="true" tabindex="-1"></a>::: {#fig-interpretation layout-ncol=2}</span>
<span id="cb3-176"><a href="#cb3-176" aria-hidden="true" tabindex="-1"></a><span class="al">![Margin with close centroids](figures/svm-interpretation-3.pdf)</span></span>
<span id="cb3-177"><a href="#cb3-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-178"><a href="#cb3-178" aria-hidden="true" tabindex="-1"></a><span class="al">![Density of the $\alpha_i$ for close centroids](figures/histo-alphai-3.pdf)</span></span>
<span id="cb3-179"><a href="#cb3-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-180"><a href="#cb3-180" aria-hidden="true" tabindex="-1"></a><span class="al">![Margin with well separated centroids](figures/svm-interpretation-10.pdf)</span></span>
<span id="cb3-181"><a href="#cb3-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-182"><a href="#cb3-182" aria-hidden="true" tabindex="-1"></a><span class="al">![Density of the $\alpha_i$ for well separated centroids](figures/histo-alphai-10.pdf)</span></span>
<span id="cb3-183"><a href="#cb3-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-184"><a href="#cb3-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-185"><a href="#cb3-185" aria-hidden="true" tabindex="-1"></a>Spectral Bridge affinity illustration involving two centroids. The bold black dots mark the centroids of each cluster, while the colored cells represent the final partition of data points. In subfigures (a) and (c), the length of each dotted grey segment is proportional to $1/2 - \alpha_i$, whereas the thin black segments are proportional to $\alpha_i$. Subfigures (b) and (d) depict the distribution of $\alpha_i$, showing the behavior when clusters are either closely positioned (a, b) or well-separated (c, d).</span>
<span id="cb3-186"><a href="#cb3-186" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-187"><a href="#cb3-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-188"><a href="#cb3-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-189"><a href="#cb3-189" aria-hidden="true" tabindex="-1"></a>Note that the criterion is local and indicates the relative difference in densities between the balls and the bridge, rather than evaluating a global score for the densities of the structures.</span>
<span id="cb3-190"><a href="#cb3-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-191"><a href="#cb3-191" aria-hidden="true" tabindex="-1"></a>Eventually, we define the bridge affinity between centroids $k$ and $l$ as the square root of the variance gain:</span>
<span id="cb3-192"><a href="#cb3-192" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-193"><a href="#cb3-193" aria-hidden="true" tabindex="-1"></a>a_{kl} =</span>
<span id="cb3-194"><a href="#cb3-194" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb3-195"><a href="#cb3-195" aria-hidden="true" tabindex="-1"></a>0, &amp; \text{if } k = l, <span class="sc">\\</span></span>
<span id="cb3-196"><a href="#cb3-196" aria-hidden="true" tabindex="-1"></a>\sqrt{\frac{\sum_{\boldsymbol{x_i} \in \mathcal{V}_k \cup \mathcal{V}_l} \alpha_i^2}{n_k + n_l}}, &amp; \text{otherwise}.</span>
<span id="cb3-197"><a href="#cb3-197" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb3-198"><a href="#cb3-198" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-199"><a href="#cb3-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-200"><a href="#cb3-200" aria-hidden="true" tabindex="-1"></a>The inclusion of the square root redefines the variance affinity measure. Rather than using the squared Euclidean norm, the affinity is interpreted as the ratio of the standard deviation to the length of the segment connecting two centroids. </span>
<span id="cb3-201"><a href="#cb3-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-202"><a href="#cb3-202" aria-hidden="true" tabindex="-1"></a>This concept can be generalized by introducing the $p$-bridge affinity for any $p \geq 1$:</span>
<span id="cb3-203"><a href="#cb3-203" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-204"><a href="#cb3-204" aria-hidden="true" tabindex="-1"></a>a_{p, kl} =</span>
<span id="cb3-205"><a href="#cb3-205" aria-hidden="true" tabindex="-1"></a>\begin{cases}</span>
<span id="cb3-206"><a href="#cb3-206" aria-hidden="true" tabindex="-1"></a>0, &amp; \text{if } k = l, <span class="sc">\\</span></span>
<span id="cb3-207"><a href="#cb3-207" aria-hidden="true" tabindex="-1"></a>\left(\frac{\sum_{\boldsymbol{x_i} \in \mathcal{V}_k \cup \mathcal{V}_l} \alpha_i^p}{n_k + n_l}\right)^{1/p}, &amp; \text{otherwise}.</span>
<span id="cb3-208"><a href="#cb3-208" aria-hidden="true" tabindex="-1"></a>\end{cases}</span>
<span id="cb3-209"><a href="#cb3-209" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-210"><a href="#cb3-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-211"><a href="#cb3-211" aria-hidden="true" tabindex="-1"></a>Both definitions are equivalent when $p = 2$. For $p = 1$, the affinity aligns directly with the SVM model previously discussed.</span>
<span id="cb3-212"><a href="#cb3-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-213"><a href="#cb3-213" aria-hidden="true" tabindex="-1"></a>To allow points with large margin to dominate and make the algorithm more robust to noise and outliers we consider the following exponential transformation:</span>
<span id="cb3-214"><a href="#cb3-214" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-215"><a href="#cb3-215" aria-hidden="true" tabindex="-1"></a>\tilde{a}_{kl} = g(a_{kl})=\exp(\gamma a_{kl}).</span>
<span id="cb3-216"><a href="#cb3-216" aria-hidden="true" tabindex="-1"></a>$${#eq-scaling}</span>
<span id="cb3-217"><a href="#cb3-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-218"><a href="#cb3-218" aria-hidden="true" tabindex="-1"></a>where $\gamma$ is a scaling factor. This factor is set to ensure a large enough separation between the final coefficients. This factor is determined by the equation:</span>
<span id="cb3-219"><a href="#cb3-219" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-220"><a href="#cb3-220" aria-hidden="true" tabindex="-1"></a>\gamma = \frac{log(𝑀)}{q_{90} - q_{10}}</span>
<span id="cb3-221"><a href="#cb3-221" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-222"><a href="#cb3-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-223"><a href="#cb3-223" aria-hidden="true" tabindex="-1"></a>where $q_{10}$ and $q_{90}$ are respectively the 10th and 90th percentiles of the original affinity matrix and $M &gt; 1$. Thus, since the transformation is order-preserving, the 90th percentile of the newly constructed matrix is $M$ times greater than the 10th percentile. By default, $M$ is arbitrarily set to a large value of $10^4$.</span>
<span id="cb3-224"><a href="#cb3-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-225"><a href="#cb3-225" aria-hidden="true" tabindex="-1"></a>This regularization is crucial: with a bounded affinity metric, exponentiation enhances the separation between low and high-density regions, controlled by a scaling parameter, as in traditional spectral clustering. Redefining the metric with a square root (or power $1/p$ for the generalized affinity) helps mitigate a converse issue, where machine error can cause numerical instability when solving the Laplacian eigenproblem, especially if values become too large. Since the range of affinity values can become too wide when the initial ratio between the largest and smallest non-zero unscaled bridge affinities is high. This transformation reduces the maximum values in the affinity matrix while preserving the metric's interpretability and distance-like properties; importantly, this adjustment is not intended for outlier detection.</span>
<span id="cb3-226"><a href="#cb3-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-227"><a href="#cb3-227" aria-hidden="true" tabindex="-1"></a><span class="fu">## Algorithm</span></span>
<span id="cb3-228"><a href="#cb3-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-229"><a href="#cb3-229" aria-hidden="true" tabindex="-1"></a>The Spectral Bridges algorithm first identifies local clusters to define Voronoï regions, computes edges with affinity weights between these regions, and ultimately cuts edges between regions with low inter-region density to determine the final clusters (see @alg-spectral-bridges and @fig-steps).</span>
<span id="cb3-230"><a href="#cb3-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-231"><a href="#cb3-231" aria-hidden="true" tabindex="-1"></a>In spectral clustering, the time complexity is usually dominated by the eigen-decomposition step, which is $O(n^3)$. However, in the case of Spectral Bridges, the k-means algorithm has a time complexity of $O(n \times m \times d)$. For datasets with large $n$, this can be more significant than the $O(m^3)$ time complexity of the Spectral Bridges eigen-decomposition. As for the affinity matrix construction, there are $m^2$ coefficients to be calculated. Each $a_{kl}$ coefficient requires the computation of $n_k + n_l$ dot products as well as the norm $\| \boldsymbol \mu_k-\boldsymbol \mu_l \|$, the latter often being negligeable. Assuming that the Voronoï regions are roughly balanced in cardinality, we have $n_k \approx \frac{n}{m}$. Since $m$ should always be less than $n$, therefore $\frac{n}{m} &gt; 1$ and the time complexity of the affinity matrix is $O(\frac{n}{m} \times m^2 \times d) = O(n \times m \times d)$ given the acceptable range of values for $m$. Nonetheless, this is rarely the bottleneck. </span>
<span id="cb3-232"><a href="#cb3-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-233"><a href="#cb3-233" aria-hidden="true" tabindex="-1"></a><span class="in">```pseudocode</span></span>
<span id="cb3-234"><a href="#cb3-234" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: alg-spectral-bridges</span></span>
<span id="cb3-235"><a href="#cb3-235" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-indent-size: "1.2em"</span></span>
<span id="cb3-236"><a href="#cb3-236" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-comment-delimiter: "//"</span></span>
<span id="cb3-237"><a href="#cb3-237" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number: true</span></span>
<span id="cb3-238"><a href="#cb3-238" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number-punc: ":"</span></span>
<span id="cb3-239"><a href="#cb3-239" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-no-end: false</span></span>
<span id="cb3-240"><a href="#cb3-240" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-placement: "htb!"</span></span>
<span id="cb3-241"><a href="#cb3-241" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-line-number: true</span></span>
<span id="cb3-242"><a href="#cb3-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-243"><a href="#cb3-243" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithm}</span></span>
<span id="cb3-244"><a href="#cb3-244" aria-hidden="true" tabindex="-1"></a><span class="in">\caption{Spectral Bridges}</span></span>
<span id="cb3-245"><a href="#cb3-245" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithmic}</span></span>
<span id="cb3-246"><a href="#cb3-246" aria-hidden="true" tabindex="-1"></a><span class="in">\Procedure{SpectralBridges}{$X, k, m$}</span></span>
<span id="cb3-247"><a href="#cb3-247" aria-hidden="true" tabindex="-1"></a><span class="in">\Comment{$X$: input dataset, $k$: number of clusters, $m$: number of Voronoï regions}</span></span>
<span id="cb3-248"><a href="#cb3-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-249"><a href="#cb3-249" aria-hidden="true" tabindex="-1"></a><span class="in">    \State \textbf{Step 1: Vector Quantization}</span></span>
<span id="cb3-250"><a href="#cb3-250" aria-hidden="true" tabindex="-1"></a><span class="in">    \State $\text{centroids}, \text{voronoiRegions} \gets$ \Call{KMeans}{$X, m$}</span></span>
<span id="cb3-251"><a href="#cb3-251" aria-hidden="true" tabindex="-1"></a><span class="in">    \Comment{Initial centroids and Voronoi regions using k-means++}</span></span>
<span id="cb3-252"><a href="#cb3-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-253"><a href="#cb3-253" aria-hidden="true" tabindex="-1"></a><span class="in">    \State \textbf{Step 2: Affinity Computation}</span></span>
<span id="cb3-254"><a href="#cb3-254" aria-hidden="true" tabindex="-1"></a><span class="in">    \State $A = \{g(a_{kl})\}_{kl} \gets$ \Call{Affinity}{$X, \text{centroids}, \text{voronoiRegions}$}</span></span>
<span id="cb3-255"><a href="#cb3-255" aria-hidden="true" tabindex="-1"></a><span class="in">    \Comment{Compute affinity matrix $A$}</span></span>
<span id="cb3-256"><a href="#cb3-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-257"><a href="#cb3-257" aria-hidden="true" tabindex="-1"></a><span class="in">    \State \textbf{Step 3: Spectral Clustering}</span></span>
<span id="cb3-258"><a href="#cb3-258" aria-hidden="true" tabindex="-1"></a><span class="in">    \Comment{Assign each region to a cluster}</span></span>
<span id="cb3-259"><a href="#cb3-259" aria-hidden="true" tabindex="-1"></a><span class="in">    \State $\text{labels} \gets$ \Call{SpectralClustering}{$A, k$}</span></span>
<span id="cb3-260"><a href="#cb3-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-261"><a href="#cb3-261" aria-hidden="true" tabindex="-1"></a><span class="in">    \State \textbf{Step 4: Propagate}</span></span>
<span id="cb3-262"><a href="#cb3-262" aria-hidden="true" tabindex="-1"></a><span class="in">    \Comment{Assign each data point to the cluster of its region}</span></span>
<span id="cb3-263"><a href="#cb3-263" aria-hidden="true" tabindex="-1"></a><span class="in">    \State $\text{clusters} \gets$ \Call{Propagate}{$X, \text{labels}, \text{voronoiRegions}$}</span></span>
<span id="cb3-264"><a href="#cb3-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-265"><a href="#cb3-265" aria-hidden="true" tabindex="-1"></a><span class="in">    \State \Return $\text{clusters}$</span></span>
<span id="cb3-266"><a href="#cb3-266" aria-hidden="true" tabindex="-1"></a><span class="in">    \Comment{Return cluster labels for data points in $X$}</span></span>
<span id="cb3-267"><a href="#cb3-267" aria-hidden="true" tabindex="-1"></a><span class="in">\EndProcedure</span></span>
<span id="cb3-268"><a href="#cb3-268" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithmic}</span></span>
<span id="cb3-269"><a href="#cb3-269" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithm}</span></span>
<span id="cb3-270"><a href="#cb3-270" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb3-271"><a href="#cb3-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-272"><a href="#cb3-272" aria-hidden="true" tabindex="-1"></a>::: {#fig-steps layout-ncol=3}</span>
<span id="cb3-273"><a href="#cb3-273" aria-hidden="true" tabindex="-1"></a><span class="al">![Vector quantization](figures/spectral-briges-1.pdf)</span></span>
<span id="cb3-274"><a href="#cb3-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-275"><a href="#cb3-275" aria-hidden="true" tabindex="-1"></a><span class="al">![Affinity computation](figures/spectral-briges-2.pdf)</span></span>
<span id="cb3-276"><a href="#cb3-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-277"><a href="#cb3-277" aria-hidden="true" tabindex="-1"></a><span class="al">![Spectral clustering](figures/spectral-briges-3-4.pdf)</span></span>
<span id="cb3-278"><a href="#cb3-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-279"><a href="#cb3-279" aria-hidden="true" tabindex="-1"></a>Illustration of the Spectral Bridges algorithm with the Iris dataset (first principal plane). The bold red dots represent the centroids of the clusters, while the colored cells indicate the final partition of the data points. Vector quantization (Step 1 of @alg-spectral-bridges), Affinity computation (Step 2 of @alg-spectral-bridges), Spectral clustering and spreading (Step 3-4 of @alg-spectral-bridges).</span>
<span id="cb3-280"><a href="#cb3-280" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-281"><a href="#cb3-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-282"><a href="#cb3-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-283"><a href="#cb3-283" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hyperparameter settings</span></span>
<span id="cb3-284"><a href="#cb3-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-285"><a href="#cb3-285" aria-hidden="true" tabindex="-1"></a>The proposed algorithm requires three input parameters: the number of clusters $K$, the number of Voronoï regions $m$, and a scaling parameter for the spectral clustering phase.</span>
<span id="cb3-286"><a href="#cb3-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-287"><a href="#cb3-287" aria-hidden="true" tabindex="-1"></a>Model selection in non-parametric settings is challenging due to the absence of predefined model parameters. It relies heavily on data-driven approaches. Metrics like the Gap Statistic <span class="co">[</span><span class="ot">@tibshirani2001estimating</span><span class="co">]</span> and the Laplacian eigengap <span class="co">[</span><span class="ot">@von2007tutorial</span><span class="co">]</span> are potential tools for hyperparameter selection.</span>
<span id="cb3-288"><a href="#cb3-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-289"><a href="#cb3-289" aria-hidden="true" tabindex="-1"></a>We propose a method for choosing the scaling parameter (see Equation @eq-scaling) that yields stable results. Selecting both $m$, the number of Voronoï regions, and $K$, the number of clusters, is difficult. We address this by adopting a heuristic: first, choose $K$, then determine $m$ using a modified Laplacian eigengap.</span>
<span id="cb3-290"><a href="#cb3-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-291"><a href="#cb3-291" aria-hidden="true" tabindex="-1"></a>If $K$ represents the true number of clusters, the affinity matrix resembles a graph adjacency matrix with $K$ connected components. This configuration is characterized by an eigengap at the $K$th eigenvalue. In Self-Tuning Spectral Clustering <span class="co">[</span><span class="ot">@zelnik2004self</span><span class="co">]</span>, the eigengap $\lambda_{K+1} - \lambda_K$ is used to evaluate clustering quality for $K$ clusters. Following a similar strategy, and assuming $K$ is known, the Laplacian eigengap at the $K$th eigenvalue can select $m$, with the scaling parameter fixed.</span>
<span id="cb3-292"><a href="#cb3-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-293"><a href="#cb3-293" aria-hidden="true" tabindex="-1"></a>Determining the optimal value of $m$ using the eigengap is not straightforward. As the affinity matrix dimension increases, the number of eigenvalues grows, reducing gaps between them. This makes direct comparisons unreliable. To address this, we use the ratio $R = (\lambda_{K+1} - \lambda_K) / \lambda_{K+1}$. This metric is bounded between 0 and 1 and measures the relative difference between consecutive eigenvalues. It facilitates meaningful comparisons across different values of $m$. A value of $R$ close to 1 suggests high clustering quality, whereas lower values indicate weaker performance.</span>
<span id="cb3-294"><a href="#cb3-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-295"><a href="#cb3-295" aria-hidden="true" tabindex="-1"></a>Using this metric, we determine a near-optimal value for $m$ by maximizing the average $R$ across possible values of $m$. Additionally, the metric enhances robustness by running the algorithm with different random seeds and selecting the clustering result with the highest normalized eigengap.</span>
<span id="cb3-296"><a href="#cb3-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-297"><a href="#cb3-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-298"><a href="#cb3-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-299"><a href="#cb3-299" aria-hidden="true" tabindex="-1"></a><span class="fu"># Numerical experiments</span></span>
<span id="cb3-300"><a href="#cb3-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-301"><a href="#cb3-301" aria-hidden="true" tabindex="-1"></a>In this section, the results obtained from testing the Spectral Bridges algorithm on various datasets, both small and large scale, including real-world and well-known synthetic datasets, are presented. These experiments assess the accuracy, time and space complexity, ease of use, robustness, and adaptability of our algorithm. We compare Spectral Bridges (SB) against several state-of-the-art methods, including k-means++ (KM) <span class="co">[</span><span class="ot">@macqueen1967some; @arthur2007kmeanspp</span><span class="co">]</span>, Expectation-Maximization (EM) <span class="co">[</span><span class="ot">@dempster1977maximum</span><span class="co">]</span>, Ward Clustering (WC) <span class="co">[</span><span class="ot">@ward1963hierarchical</span><span class="co">]</span>, DBSCAN (DB) <span class="co">[</span><span class="ot">@ester1996density</span><span class="co">]</span> and GIT <span class="co">[</span><span class="ot">@gao2021git</span><span class="co">]</span>. This comparison establishes baselines across centroid-based clustering algorithms, hierarchical methods, and density-based methods. </span>
<span id="cb3-302"><a href="#cb3-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-303"><a href="#cb3-303" aria-hidden="true" tabindex="-1"></a>The algorithms are evaluated on both raw and Principal Component Analysis processed (PCA-processed) data with varying dimensionality. For synthetic datasets, Gaussian and/or uniform noise is introduced to assess the robustness of the algorithm.</span>
<span id="cb3-304"><a href="#cb3-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-305"><a href="#cb3-305" aria-hidden="true" tabindex="-1"></a><span class="fu">## Datasets</span></span>
<span id="cb3-306"><a href="#cb3-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-307"><a href="#cb3-307" aria-hidden="true" tabindex="-1"></a><span class="fu">### Real-world data</span></span>
<span id="cb3-308"><a href="#cb3-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-309"><a href="#cb3-309" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**MNIST**: A large dataset containing 60,000 handwritten digit images in ten balanced classes, commonly used for image processing benchmarks. Each image consists of $28 \times 28 = 784$ pixels.</span>
<span id="cb3-310"><a href="#cb3-310" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**UCI ML Breast Cancer Wisconsin**: A dataset featuring computed attributes from digitized images of fine needle aspirates (FNA) of breast masses, used to predict whether a tumor is malignant or benign.</span>
<span id="cb3-311"><a href="#cb3-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-312"><a href="#cb3-312" aria-hidden="true" tabindex="-1"></a><span class="fu">### Synthetic data</span></span>
<span id="cb3-313"><a href="#cb3-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-314"><a href="#cb3-314" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Impossible**: A synthetic dataset designed to challenge clustering algorithms with complex patterns.</span>
<span id="cb3-315"><a href="#cb3-315" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Moons**: A two-dimensional dataset with two interleaving half-circles.</span>
<span id="cb3-316"><a href="#cb3-316" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Circles**: A synthetic dataset of points arranged in two non-linearly separable circles.</span>
<span id="cb3-317"><a href="#cb3-317" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Smile**: A synthetic dataset with points arranged in the shape of a smiling face, used to test the separation of non-linearly separable data.</span>
<span id="cb3-318"><a href="#cb3-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-319"><a href="#cb3-319" aria-hidden="true" tabindex="-1"></a><span class="fu">### Datasets Summary &amp; Class Balance</span></span>
<span id="cb3-320"><a href="#cb3-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-321"><a href="#cb3-321" aria-hidden="true" tabindex="-1"></a>| **Dataset**    | **#Dims** | **#Samples** | **#Classes** | **Class Proportions**                     |</span>
<span id="cb3-322"><a href="#cb3-322" aria-hidden="true" tabindex="-1"></a>| -------------- | --------- | ------------ | ------------ | ----------------------------------------- |</span>
<span id="cb3-323"><a href="#cb3-323" aria-hidden="true" tabindex="-1"></a>| MNIST          | 784       | 60000        | 10           | 9.9%, 11.2%, 9.9%, 10.3%, 9.7%, 9%, 9.9%, 10.4%, 9.7%, 9.9% |</span>
<span id="cb3-324"><a href="#cb3-324" aria-hidden="true" tabindex="-1"></a>| Breast Cancer  | 30        | 569          | 2            | 37.3%, 62.7%                              |</span>
<span id="cb3-325"><a href="#cb3-325" aria-hidden="true" tabindex="-1"></a>| Impossible     | 2         | 3594         | 7            | 24.8%, 18.8%, 11.3%, 7.5%, 12.5%, 12.5%, 12.5% |</span>
<span id="cb3-326"><a href="#cb3-326" aria-hidden="true" tabindex="-1"></a>| Moons          | 2         | 1000         | 2            | 50%, 50%                                  |</span>
<span id="cb3-327"><a href="#cb3-327" aria-hidden="true" tabindex="-1"></a>| Circles        | 2         | 1000         | 2            | 50%, 50%                                  |</span>
<span id="cb3-328"><a href="#cb3-328" aria-hidden="true" tabindex="-1"></a>| Smile          | 2         | 1000         | 4            | 25%, 25%, 25%, 25%                        |</span>
<span id="cb3-329"><a href="#cb3-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-330"><a href="#cb3-330" aria-hidden="true" tabindex="-1"></a>Table: Datasets Summary &amp; Class Balance</span>
<span id="cb3-331"><a href="#cb3-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-332"><a href="#cb3-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-333"><a href="#cb3-333" aria-hidden="true" tabindex="-1"></a>Class proportions are presented in ascending order starting from label $0$.</span>
<span id="cb3-334"><a href="#cb3-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-335"><a href="#cb3-335" aria-hidden="true" tabindex="-1"></a><span class="fu">## Metrics</span></span>
<span id="cb3-336"><a href="#cb3-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-337"><a href="#cb3-337" aria-hidden="true" tabindex="-1"></a>To evaluate the performance of the clustering algorithm, the Adjusted Rand Index (ARI) <span class="co">[</span><span class="ot">@halkidi2002cluster</span><span class="co">]</span> and Normalized Mutual Information (NMI) <span class="co">[</span><span class="ot">@cover1991information</span><span class="co">]</span> are used. ARI measures the similarity between two clustering results, ranging from -0.5 to 1, with 1 indicating perfect agreement. NMI ranges from 0 to 1, with higher values indicating better clustering quality. In some tests, the variability of scores across multiple runs is also reported due to the random initialization in k-means, though k-means++ generally provides stable and reproducible results.</span>
<span id="cb3-338"><a href="#cb3-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-339"><a href="#cb3-339" aria-hidden="true" tabindex="-1"></a><span class="fu">## Platform</span></span>
<span id="cb3-340"><a href="#cb3-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-341"><a href="#cb3-341" aria-hidden="true" tabindex="-1"></a>All experiments were conducted on an Archlinux machine with Linux 6.9.3 Kernel, 8GB of RAM, and an AMD Ryzen 3 7320U processor.</span>
<span id="cb3-342"><a href="#cb3-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-343"><a href="#cb3-343" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sensitivity to hyperparameters</span></span>
<span id="cb3-344"><a href="#cb3-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-345"><a href="#cb3-345" aria-hidden="true" tabindex="-1"></a>The hyperparameters of the Spectral Bridges algorithm were based on the size of each dataset, $n$, and the number of clusters, $K$.</span>
<span id="cb3-346"><a href="#cb3-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-347"><a href="#cb3-347" aria-hidden="true" tabindex="-1"></a>To better grasp the sensitivity regarding to $m$, the number of Voronoï cells, Spectral Bridges was run on the PCA $h = 32$ embedded MNIST dataset with varying values of $m \in <span class="sc">\{</span>10, 120, 230, 340, 450, 560, 670, 780, 890, 1000 <span class="sc">\}</span>$. The case $m = 10$ is equivalent to the k-means++ algorithm. ARI and NMI scores are recorded over 20 consecutive iterations and subsequently plotted. As shown by @fig-m-vs-score, the accuracy seems to be consistently increasing with values of $m$, with the largest observed gap occurring between values of $m = 10$ and $m = 120$, and flattening thereafter, indicating a tremendous improvement over the classical k-means++ framework even for empirically suboptimal hyperparameter values. </span>
<span id="cb3-348"><a href="#cb3-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-349"><a href="#cb3-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-350"><a href="#cb3-350" aria-hidden="true" tabindex="-1"></a><span class="al">![ARI and NMI scores of Spectral Bridges with varying values of $m$.](figures/nodes_vs_score.pdf)</span>{#fig-m-vs-score}</span>
<span id="cb3-351"><a href="#cb3-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-352"><a href="#cb3-352" aria-hidden="true" tabindex="-1"></a>For other algorithms, such as DBSCAN, labels were used to determine the best hyperparameter values to compare our method against the "best case scenario", thus putting  the Spectral Bridges algorithm at a voluntary disadvantage.</span>
<span id="cb3-353"><a href="#cb3-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-354"><a href="#cb3-354" aria-hidden="true" tabindex="-1"></a><span class="fu">## Time complexity</span></span>
<span id="cb3-355"><a href="#cb3-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-356"><a href="#cb3-356" aria-hidden="true" tabindex="-1"></a>To assess the algorithm's time complexity, the average execution times over 50 runs were computed for varying numbers of Voronoï regions $m$ as well as dataset sizes. With a constant number of clusters $K = 5$ and an embedding dimension of $d = 10$, the results (see @fig-time-complexity) highlight Spectral Bridges algorihtm's efficacy. As discussed previously, we observe a linear relationship between $m$ and the execution time because the matrix construction is highly optimized and the time taken is almost negligeable compared to that of the initial k-means++ centroids initalization.</span>
<span id="cb3-357"><a href="#cb3-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-358"><a href="#cb3-358" aria-hidden="true" tabindex="-1"></a>::: {#fig-time-complexity layout-ncol=2}</span>
<span id="cb3-359"><a href="#cb3-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-360"><a href="#cb3-360" aria-hidden="true" tabindex="-1"></a><span class="al">![Varying $n$, fixed $m = 10$](figures/size_vs_time.pdf)</span></span>
<span id="cb3-361"><a href="#cb3-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-362"><a href="#cb3-362" aria-hidden="true" tabindex="-1"></a><span class="al">![Varying $m$, fixed $n = 5000$](figures/nodes_vs_time.pdf)</span></span>
<span id="cb3-363"><a href="#cb3-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-364"><a href="#cb3-364" aria-hidden="true" tabindex="-1"></a>Average time taken per model fit.</span>
<span id="cb3-365"><a href="#cb3-365" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-366"><a href="#cb3-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-367"><a href="#cb3-367" aria-hidden="true" tabindex="-1"></a><span class="fu">## Accuracy</span></span>
<span id="cb3-368"><a href="#cb3-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-369"><a href="#cb3-369" aria-hidden="true" tabindex="-1"></a>The algorithm's accuracy was first evaluated on the MNIST dataset. Metrics were collected to compare our method with k-means++, EM, and Ward clustering. Metrics were estimated by computing the empirical average over 10 consecutive runs for each method. Due to limited computational resources, we randomly selected a sample of 20,000 data points (one-third of the total) for each run, on which all algorithms were trained and tested. To ensure reproducibility, a fixed random seed was set at the beginning of all scripts. Note, however, that this does not imply centroids were initialized identically for centroid based methods, as these may vary according to the implementation of each tested algorithm.</span>
<span id="cb3-370"><a href="#cb3-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-371"><a href="#cb3-371" aria-hidden="true" tabindex="-1"></a>Let $h$ denote the embedding dimension of the dataset. Spectral Bridges was tested both on the raw MNIST dataset without preprocessing ($h = 784$) and after reducing its dimension using PCA to $h \in <span class="sc">\{</span>8, 16, 32, 64<span class="sc">\}</span>$ (see @fig-mnist-pca-scores).</span>
<span id="cb3-372"><a href="#cb3-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-373"><a href="#cb3-373" aria-hidden="true" tabindex="-1"></a><span class="al">![ARI and NMI scores of k-means++ (pink), EM (green), Ward Clustering (red), GIT (blue), and Spectral Bridges (purple) on PCA embedding and full MNIST.](figures/mnist_pca_summary.pdf)</span>{#fig-mnist-pca-scores}</span>
<span id="cb3-374"><a href="#cb3-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-375"><a href="#cb3-375" aria-hidden="true" tabindex="-1"></a>Furthermore, the proposed algorithm was also tested on the same MNIST dataset after reducing its dimension to $h \in <span class="sc">\{</span>2, 4, 8, 16<span class="sc">\}</span>$ using UMAP <span class="co">[</span><span class="ot">@McInnes2018</span><span class="co">]</span>, a state-of-the-art non-linear dimension reduction algorithm (see @fig-mnist-umap-scores). To further improve the clustering performance of Spectral Bridges, the <span class="in">`fit_select`</span> method was employed. This method effectively trains the algorithm with multiple initializations and selects the one with the largest normalized eigengap (refer to the **Hyperparameter settings** section).</span>
<span id="cb3-376"><a href="#cb3-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-377"><a href="#cb3-377" aria-hidden="true" tabindex="-1"></a><span class="al">![ARI and NMI scores of k-means++ (pink), EM (green), Ward Clustering (red), GIT (blue), Spectral Bridges (purple) on UMAP embedding](figures/mnist_umap_summary.pdf)</span>{#fig-mnist-umap-scores}</span>
<span id="cb3-378"><a href="#cb3-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-379"><a href="#cb3-379" aria-hidden="true" tabindex="-1"></a>Note the Spectral Bridges is substantially better than other traditional methods and shines even with quite simple dimension reduction algorithms.</span>
<span id="cb3-380"><a href="#cb3-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-381"><a href="#cb3-381" aria-hidden="true" tabindex="-1"></a>For visualization purposes, the predicted clusters by Spectral Bridges and k-means++ were projected using UMAP to compare them against the ground truth labels and to better understand the cluster shapes (see @fig-MNIST). Note this projection was not used in the experiments as an embedding, and thus does not play any role in the clustering process itself. As a matter of fact, the embedding used was obtained with Principal Componant Analysis (PCA), $h = 32$ and 250 Voronoï regions. Note that the label colors match the legend only in the case of the ground truth data. Indeed, the ordering of the labels have no significance on clustering quality.</span>
<span id="cb3-382"><a href="#cb3-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-383"><a href="#cb3-383" aria-hidden="true" tabindex="-1"></a>::: {#fig-MNIST layout-ncol=3}</span>
<span id="cb3-384"><a href="#cb3-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-385"><a href="#cb3-385" aria-hidden="true" tabindex="-1"></a><span class="al">![k-means++](figures/KMumap.pdf)</span></span>
<span id="cb3-386"><a href="#cb3-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-387"><a href="#cb3-387" aria-hidden="true" tabindex="-1"></a><span class="al">![Spectral Bridges](figures/SBumap.pdf)</span></span>
<span id="cb3-388"><a href="#cb3-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-389"><a href="#cb3-389" aria-hidden="true" tabindex="-1"></a><span class="al">![Ground Truth](figures/GTumap.pdf)</span></span>
<span id="cb3-390"><a href="#cb3-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-391"><a href="#cb3-391" aria-hidden="true" tabindex="-1"></a>UMAP projection of predicted clusters against the ground truth labels.</span>
<span id="cb3-392"><a href="#cb3-392" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-393"><a href="#cb3-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-394"><a href="#cb3-394" aria-hidden="true" tabindex="-1"></a>The Spectral Bridges algorithm was also put to the test against the same competitors using scikit-learn's UCI Breast Cancer data. Once again, this new method performs well although the advantage is not as obvious in this case (see @fig-cancer-scores). However, in none of our tests has it ranked worse than k-means++. The results are displayed as a boxplot generated from 200 iterations of each algorithm using a different seed, in order to better grasp the variability lying in the seed dependent nature of the k-means++, Expectation Maximization and Spectral Bridges algorithms.</span>
<span id="cb3-395"><a href="#cb3-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-396"><a href="#cb3-396" aria-hidden="true" tabindex="-1"></a><span class="al">![ARI and NMI scores of k-means++ (blue), EM (green), Ward Clustering (red), and Spectral Bridges (purple) on the UCI Breast Cancer dataset.](figures/cancer_summary.pdf)</span>{#fig-cancer-scores}</span>
<span id="cb3-397"><a href="#cb3-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-398"><a href="#cb3-398" aria-hidden="true" tabindex="-1"></a>Since the Spectral Bridges algorithm is expected to excel at discerning complex and intricate cluster structures, an array of four toy datasets was collected, as illustrated in @fig-toy-datasets.</span>
<span id="cb3-399"><a href="#cb3-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-400"><a href="#cb3-400" aria-hidden="true" tabindex="-1"></a>::: {#fig-toy-datasets layout-ncol=4}</span>
<span id="cb3-401"><a href="#cb3-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-402"><a href="#cb3-402" aria-hidden="true" tabindex="-1"></a><span class="al">![Impossible](figures/impossible.pdf)</span></span>
<span id="cb3-403"><a href="#cb3-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-404"><a href="#cb3-404" aria-hidden="true" tabindex="-1"></a><span class="al">![Moons](figures/moons.pdf)</span></span>
<span id="cb3-405"><a href="#cb3-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-406"><a href="#cb3-406" aria-hidden="true" tabindex="-1"></a><span class="al">![Circles](figures/circles.pdf)</span></span>
<span id="cb3-407"><a href="#cb3-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-408"><a href="#cb3-408" aria-hidden="true" tabindex="-1"></a><span class="al">![Smile](figures/smile.pdf)</span></span>
<span id="cb3-409"><a href="#cb3-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-410"><a href="#cb3-410" aria-hidden="true" tabindex="-1"></a>Four toy datasets.</span>
<span id="cb3-411"><a href="#cb3-411" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-412"><a href="#cb3-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-413"><a href="#cb3-413" aria-hidden="true" tabindex="-1"></a>Multiple algorithms, including the proposed one, were benchmarked in the exact same manner as for the UCI Breast Cancer data. The results show that the proposed method outperforms all tested algorithms (DBSCAN, k-means++, Expectation Maximization, and Ward Clustering) while requiring few hyperparameters. As previously discussed, DBSCAN's parameters were optimized using the ground truth labels to represent a best-case scenario; however, in practical applications, suboptimal performance is more likely. Despite this optimization, the Spectral-Bridge algorithm still demonstrates superior ability to capture and represent the underlying cluster structures.</span>
<span id="cb3-414"><a href="#cb3-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-415"><a href="#cb3-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-416"><a href="#cb3-416" aria-hidden="true" tabindex="-1"></a><span class="al">![ARI and NMI scores of Spectral Bridges and competitors on standard synthetic toy datasets.](figures/synthetic_summary.pdf)</span>{#fig-synthetic-scores}</span>
<span id="cb3-417"><a href="#cb3-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-418"><a href="#cb3-418" aria-hidden="true" tabindex="-1"></a>\newpage</span>
<span id="cb3-419"><a href="#cb3-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-420"><a href="#cb3-420" aria-hidden="true" tabindex="-1"></a><span class="fu">## Noise robustness</span></span>
<span id="cb3-421"><a href="#cb3-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-422"><a href="#cb3-422" aria-hidden="true" tabindex="-1"></a>To evaluate the noise robustness of the algorithm, two experimental setups were devised: one involved introducing Gaussian-distributed perturbations to the data, and the other involved concatenating uniformly distributed points within a predefined rectangular region (determined by the span of the dataset) to the existing dataset. As illustrated in @fig-noise-robustness, the tests demonstrate that in both scenarios, the algorithm exhibits a high degree of insensitivity to noise.</span>
<span id="cb3-423"><a href="#cb3-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-424"><a href="#cb3-424" aria-hidden="true" tabindex="-1"></a>::: {#fig-noise-robustness layout-ncol=3}</span>
<span id="cb3-425"><a href="#cb3-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-426"><a href="#cb3-426" aria-hidden="true" tabindex="-1"></a><span class="al">![Clean](figures/clean_impossible.pdf)</span></span>
<span id="cb3-427"><a href="#cb3-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-428"><a href="#cb3-428" aria-hidden="true" tabindex="-1"></a><span class="al">![Uniform noise](figures/uniform_noise_impossible.pdf)</span></span>
<span id="cb3-429"><a href="#cb3-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-430"><a href="#cb3-430" aria-hidden="true" tabindex="-1"></a><span class="al">![Gaussian noise](figures/gaussian_noise_impossible.pdf)</span></span>
<span id="cb3-431"><a href="#cb3-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-432"><a href="#cb3-432" aria-hidden="true" tabindex="-1"></a>Three representations of the algorithm's predicted cluster centers are displayed as colored dots, with each point of the Impossible dataset shown as a small black dot. In the left graph, the dataset is unmodified. In the center graph, 250 uniformly distributed samples were added. In the right graph, Gaussian noise perturbations with $\sigma = 0.1$ were applied.</span>
<span id="cb3-433"><a href="#cb3-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-434"><a href="#cb3-434" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-435"><a href="#cb3-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-436"><a href="#cb3-436" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusive remarks</span></span>
<span id="cb3-437"><a href="#cb3-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-438"><a href="#cb3-438" aria-hidden="true" tabindex="-1"></a>Spectral Bridges is an original clustering algorithm which presents a novel approach by integrating the strengths of traditional k-means and spectral clustering frameworks. This algorithm utilizes a simple affinity measure for spectral clustering, which is derived from the minimal margin between pairs of Voronoï regions. </span>
<span id="cb3-439"><a href="#cb3-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-440"><a href="#cb3-440" aria-hidden="true" tabindex="-1"></a>The algorithm demonstrates scalability, handling large datasets efficiently through a balanced computational complexity between the k-means clustering and eigen-decomposition steps. As a non-parametric method, Spectral Bridges does not rely on strong assumptions about data distribution, enhancing its versatility across various data types. It performs exceptionally well with both synthetic and real-world data and consistently outperforms conventional clustering algorithms such as k-means, DBSCAN, and mixture models. </span>
<span id="cb3-441"><a href="#cb3-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-442"><a href="#cb3-442" aria-hidden="true" tabindex="-1"></a>The design of Spectral Bridges ensures robustness to noise, a significant advantage in real-world applications. Additionally, the algorithm requires minimal hyperparameters, primarily the number of Voronoï regions, making it straightforward to tune and deploy. </span>
<span id="cb3-443"><a href="#cb3-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-444"><a href="#cb3-444" aria-hidden="true" tabindex="-1"></a>Furthermore, Spectral Bridges can be kernelized, allowing it to handle data in similarity space directly, which enhances its flexibility and applicability. Overall, Spectral Bridges is a powerful, robust, and scalable clustering algorithm that offers significant improvements over traditional methods, making it an excellent tool for advanced clustering tasks across numerous domains.</span>
<span id="cb3-445"><a href="#cb3-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-446"><a href="#cb3-446" aria-hidden="true" tabindex="-1"></a><span class="fu"># Appendix {.appendix}</span></span>
<span id="cb3-447"><a href="#cb3-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-448"><a href="#cb3-448" aria-hidden="true" tabindex="-1"></a><span class="fu">## Derivation of the bridge affinity {#gain}</span></span>
<span id="cb3-449"><a href="#cb3-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-450"><a href="#cb3-450" aria-hidden="true" tabindex="-1"></a>We denote a bridge as a segment connecting two centroids $\boldsymbol \mu_k$ and $\boldsymbol \mu_l$. The inertia of a bridge between $\mathcal{V}_k$ and $\mathcal{V}_l$ is defined as </span>
<span id="cb3-451"><a href="#cb3-451" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-452"><a href="#cb3-452" aria-hidden="true" tabindex="-1"></a>B_{kl} = \sum_{\boldsymbol x_i\in \mathcal{V}_k \cup \mathcal{V}_l} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2,</span>
<span id="cb3-453"><a href="#cb3-453" aria-hidden="true" tabindex="-1"></a>$$ where </span>
<span id="cb3-454"><a href="#cb3-454" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-455"><a href="#cb3-455" aria-hidden="true" tabindex="-1"></a>\boldsymbol p_{kl}(\boldsymbol x_i) = \boldsymbol \mu_{k} + t_i(\boldsymbol \mu_{l} - \boldsymbol \mu_{k}),</span>
<span id="cb3-456"><a href="#cb3-456" aria-hidden="true" tabindex="-1"></a>$$ with $$</span>
<span id="cb3-457"><a href="#cb3-457" aria-hidden="true" tabindex="-1"></a>t_i = \min\left(1, \max\left(0, \frac{\langle \boldsymbol x_i - \boldsymbol \mu_k | \boldsymbol \mu_l - \boldsymbol \mu_k\rangle}{\|  \boldsymbol \mu_l - \boldsymbol \mu_k \|^2}\right)\right). </span>
<span id="cb3-458"><a href="#cb3-458" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb3-459"><a href="#cb3-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-460"><a href="#cb3-460" aria-hidden="true" tabindex="-1"></a>$B_{kl}$, the bridge inertia between centroids $k$ and $l$, can be expressed as the sum of three terms, which represents the projection onto each centroïds and onto the segment:</span>
<span id="cb3-461"><a href="#cb3-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-462"><a href="#cb3-462" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-463"><a href="#cb3-463" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb3-464"><a href="#cb3-464" aria-hidden="true" tabindex="-1"></a>B_{kl} &amp;=&amp; \sum_{i \mid t_i=0} \|\boldsymbol x_i - \boldsymbol \mu_k\|^2  + \sum_{i \mid t_i=1} \|\boldsymbol x_i - \boldsymbol \mu_l\|^2 + \sum_{i \mid t_i\in ]0,1[} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2.</span>
<span id="cb3-465"><a href="#cb3-465" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb3-466"><a href="#cb3-466" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-467"><a href="#cb3-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-468"><a href="#cb3-468" aria-hidden="true" tabindex="-1"></a>The last term may be decomposed in two parts corresponding to the points of the two Voronoï regions which are projected on the segment:</span>
<span id="cb3-469"><a href="#cb3-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-470"><a href="#cb3-470" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-471"><a href="#cb3-471" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb3-472"><a href="#cb3-472" aria-hidden="true" tabindex="-1"></a>\sum_{i \mid t_i\in ]0,1<span class="co">[</span><span class="ot">} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2 &amp;=&amp; \sum_{i \mid t_i\in </span><span class="co">]</span>0,\frac{1}{2}[} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2 + \sum_{i \mid t_i\in [\frac{1}{2},1[} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2<span class="sc">\\</span></span>
<span id="cb3-473"><a href="#cb3-473" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb3-474"><a href="#cb3-474" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-475"><a href="#cb3-475" aria-hidden="true" tabindex="-1"></a>and each part further decomposed using Pythagore </span>
<span id="cb3-476"><a href="#cb3-476" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-477"><a href="#cb3-477" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb3-478"><a href="#cb3-478" aria-hidden="true" tabindex="-1"></a>\sum_{i \mid t_i\in ]0,\frac{1}{2}<span class="co">[</span><span class="ot">} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2 &amp;=&amp; \sum_{i \mid t_i\in </span><span class="co">]</span>0,\frac{1}{2}<span class="co">[</span><span class="ot">} \|\boldsymbol x_i - \boldsymbol \mu_k\|^2 - \sum_{i \mid t_i\in </span><span class="co">]</span>0,\frac{1}{2}[} \|\boldsymbol \mu_k - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2<span class="sc">\\</span></span>
<span id="cb3-479"><a href="#cb3-479" aria-hidden="true" tabindex="-1"></a>&amp;=&amp; \sum_{i \mid t_i\in ]0,\frac{1}{2}<span class="co">[</span><span class="ot">} \|\boldsymbol x_i - \boldsymbol \mu_k\|^2 - \sum_{i \mid t_i\in </span><span class="co">]</span>0,\frac{1}{2}[} \|t_i (\boldsymbol \mu_k - \boldsymbol \mu_{l})\|^2,</span>
<span id="cb3-480"><a href="#cb3-480" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb3-481"><a href="#cb3-481" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-482"><a href="#cb3-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-483"><a href="#cb3-483" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-484"><a href="#cb3-484" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb3-485"><a href="#cb3-485" aria-hidden="true" tabindex="-1"></a>\sum_{i \mid t_i\in ]\frac{1}{2},1<span class="co">[</span><span class="ot">} \|\boldsymbol x_i - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2 &amp;=&amp; \sum_{i \mid t_i\in </span><span class="co">]</span>0,\frac{1}{2}<span class="co">[</span><span class="ot">} \|\boldsymbol x_i - \boldsymbol \mu_l\|^2 - \sum_{i \mid t_i\in </span><span class="co">]</span>0,\frac{1}{2}[} \|\boldsymbol \mu_l - \boldsymbol p_{kl}(\boldsymbol x_i)\|^2<span class="sc">\\</span></span>
<span id="cb3-486"><a href="#cb3-486" aria-hidden="true" tabindex="-1"></a>&amp;=&amp; \sum_{i \mid t_i\in ]\frac{1}{2},1<span class="co">[</span><span class="ot">} \|\boldsymbol x_i - \boldsymbol \mu_k\|^2 - \sum_{i \mid t_i\in </span><span class="co">]</span>0,\frac{1}{2}[} \|(1-t_i) (\boldsymbol \mu_k - \boldsymbol \mu_{l})\|^2</span>
<span id="cb3-487"><a href="#cb3-487" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb3-488"><a href="#cb3-488" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-489"><a href="#cb3-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-490"><a href="#cb3-490" aria-hidden="true" tabindex="-1"></a>Thus </span>
<span id="cb3-491"><a href="#cb3-491" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-492"><a href="#cb3-492" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb3-493"><a href="#cb3-493" aria-hidden="true" tabindex="-1"></a>B_{kl}- I_{kl} &amp;=  \sum_{i \mid t_i\in ]0,\frac{1}{2}<span class="co">[</span><span class="ot">} t_i^2 \|\boldsymbol \mu_k - \boldsymbol \mu_l\|^2 + \sum_{i \mid t_i\in </span><span class="co">]</span>\frac{1}{2},1[} (1-t_i)^2 \|\boldsymbol \mu_k - \boldsymbol \mu_l\|^2,<span class="sc">\\</span></span>
<span id="cb3-494"><a href="#cb3-494" aria-hidden="true" tabindex="-1"></a>\frac{B_{kl}- I_{kl}}{\|\boldsymbol \mu_k - \boldsymbol \mu_l\|^2} &amp;= \sum_{i \mid t_i\in ]0,\frac{1}{2}<span class="co">[</span><span class="ot">} t_i^2  + \sum_{i \mid t_i\in </span><span class="co">]</span>\frac{1}{2},1[} (1-t_i)^2, <span class="sc">\\</span></span>
<span id="cb3-495"><a href="#cb3-495" aria-hidden="true" tabindex="-1"></a>\frac{B_{kl}- I_{kl}}{(n_k+n_l)\|\boldsymbol \mu_k - \boldsymbol \mu_l\|^2} &amp;= \frac{\sum_{\boldsymbol{x_i} \in \mathcal V_k} \langle \boldsymbol{x_i} - \boldsymbol{\mu}_k \vert \boldsymbol{\mu}_l - \boldsymbol{\mu}_k \rangle_+^2 + \sum_{\boldsymbol{x_i} \in \mathcal V_l} \langle \boldsymbol{x_i} - \boldsymbol{\mu}_l \vert \boldsymbol{\mu}_k - \boldsymbol{\mu}_l\rangle_+^2}{(n_k+n_l)\|\boldsymbol \mu_k - \boldsymbol \mu_l\|^4}.</span>
<span id="cb3-496"><a href="#cb3-496" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb3-497"><a href="#cb3-497" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb3-498"><a href="#cb3-498" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-499"><a href="#cb3-499" aria-hidden="true" tabindex="-1"></a><span class="fu">## Code</span></span>
<span id="cb3-500"><a href="#cb3-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-501"><a href="#cb3-501" aria-hidden="true" tabindex="-1"></a><span class="fu">### Implementation </span></span>
<span id="cb3-502"><a href="#cb3-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-503"><a href="#cb3-503" aria-hidden="true" tabindex="-1"></a>Numerical experiments have been conducted in Python. The python scripts to reproduce the simulations and figures are available at <span class="ot">&lt;https://github.com/flheight/Spectral-Bridges&gt;</span>.  The Spectral Bridge algorithm is implemented both in </span>
<span id="cb3-504"><a href="#cb3-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-505"><a href="#cb3-505" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Python: <span class="ot">&lt;https://pypi.org/project/spectral-bridges&gt;</span>, and</span>
<span id="cb3-506"><a href="#cb3-506" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>R: <span class="ot">&lt;https://github.com/cambroise/spectral-bridges-Rpackage&gt;</span>.</span>
<span id="cb3-507"><a href="#cb3-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-508"><a href="#cb3-508" aria-hidden="true" tabindex="-1"></a><span class="fu">### Affinity matrix computation</span></span>
<span id="cb3-509"><a href="#cb3-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-510"><a href="#cb3-510" aria-hidden="true" tabindex="-1"></a>Taking a closer look at the second step of @alg-spectral-bridges, that is the affinity matrix calculation with a $O(n \times m \times d)$ time complexity, most operations can be parallelized leaving a single loop, bundling together $m^2$ dot products into only $m$ matrix multiplications, thus allowing for an efficient construction in both high and low level programming languages. Though the complexity of the algorithm remains unchanged, libraries such as Basic Linear Algebra Subprograms can render the calculations orders of magnitude faster. Moreover, the symmetrical nature of the bridge affinity can be used to effectively halve the computation time.</span>
<span id="cb3-511"><a href="#cb3-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-512"><a href="#cb3-512" aria-hidden="true" tabindex="-1"></a>The calculation of the affinity matrix is highlighted by the Python code @lst-code-affinity. Though it could be even more optimized, the following code snippet is approximately 200 times faster than a naive implementation on a small dataset comprised of $n = 3594$, $d = 2$ points, and a value of $m = 250$.</span>
<span id="cb3-513"><a href="#cb3-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-514"><a href="#cb3-514" aria-hidden="true" tabindex="-1"></a>Notice that the Python code is significantly faster than the R code.</span>
<span id="cb3-515"><a href="#cb3-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-516"><a href="#cb3-516" aria-hidden="true" tabindex="-1"></a><span class="in">```{python affinity, python.reticulate = FALSE}</span></span>
<span id="cb3-517"><a href="#cb3-517" aria-hidden="true" tabindex="-1"></a><span class="in">#| lst-label: lst-code-affinity</span></span>
<span id="cb3-518"><a href="#cb3-518" aria-hidden="true" tabindex="-1"></a><span class="in">#| lst-cap: "Python code for affinity matrix computation"</span></span>
<span id="cb3-519"><a href="#cb3-519" aria-hidden="true" tabindex="-1"></a><span class="in">#| echo: true</span></span>
<span id="cb3-520"><a href="#cb3-520" aria-hidden="true" tabindex="-1"></a><span class="in">#| eval: false</span></span>
<span id="cb3-521"><a href="#cb3-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-522"><a href="#cb3-522" aria-hidden="true" tabindex="-1"></a><span class="in">#Initialize the matrix as empty</span></span>
<span id="cb3-523"><a href="#cb3-523" aria-hidden="true" tabindex="-1"></a><span class="in">affinity = np.empty((self.n_nodes, self.n_nodes))</span></span>
<span id="cb3-524"><a href="#cb3-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-525"><a href="#cb3-525" aria-hidden="true" tabindex="-1"></a><span class="in">#Center each region</span></span>
<span id="cb3-526"><a href="#cb3-526" aria-hidden="true" tabindex="-1"></a><span class="in">X_centered = [</span></span>
<span id="cb3-527"><a href="#cb3-527" aria-hidden="true" tabindex="-1"></a><span class="in">    np.array(</span></span>
<span id="cb3-528"><a href="#cb3-528" aria-hidden="true" tabindex="-1"></a><span class="in">        X[kmeans.labels_ == i] - kmeans.cluster_centers_[i],</span></span>
<span id="cb3-529"><a href="#cb3-529" aria-hidden="true" tabindex="-1"></a><span class="in">        dtype=np.float32,</span></span>
<span id="cb3-530"><a href="#cb3-530" aria-hidden="true" tabindex="-1"></a><span class="in">        order="F",</span></span>
<span id="cb3-531"><a href="#cb3-531" aria-hidden="true" tabindex="-1"></a><span class="in">    )</span></span>
<span id="cb3-532"><a href="#cb3-532" aria-hidden="true" tabindex="-1"></a><span class="in">    for i in range(self.n_nodes)</span></span>
<span id="cb3-533"><a href="#cb3-533" aria-hidden="true" tabindex="-1"></a><span class="in">]</span></span>
<span id="cb3-534"><a href="#cb3-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-535"><a href="#cb3-535" aria-hidden="true" tabindex="-1"></a><span class="in">#Cardinal calculation</span></span>
<span id="cb3-536"><a href="#cb3-536" aria-hidden="true" tabindex="-1"></a><span class="in">counts = np.array([X_centered[i].shape[0] for i in range(self.n_nodes)])</span></span>
<span id="cb3-537"><a href="#cb3-537" aria-hidden="true" tabindex="-1"></a><span class="in">counts = counts[None, :] + counts[:, None]</span></span>
<span id="cb3-538"><a href="#cb3-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-539"><a href="#cb3-539" aria-hidden="true" tabindex="-1"></a><span class="in">#Calculate the affinity</span></span>
<span id="cb3-540"><a href="#cb3-540" aria-hidden="true" tabindex="-1"></a><span class="in">for i in range(self.n_nodes):</span></span>
<span id="cb3-541"><a href="#cb3-541" aria-hidden="true" tabindex="-1"></a><span class="in">    segments = np.asfortranarray(</span></span>
<span id="cb3-542"><a href="#cb3-542" aria-hidden="true" tabindex="-1"></a><span class="in">        kmeans.cluster_centers_ - kmeans.cluster_centers_[i]</span></span>
<span id="cb3-543"><a href="#cb3-543" aria-hidden="true" tabindex="-1"></a><span class="in">    )</span></span>
<span id="cb3-544"><a href="#cb3-544" aria-hidden="true" tabindex="-1"></a><span class="in">    dists = np.einsum("ij,ij-&gt;i", segments, segments)</span></span>
<span id="cb3-545"><a href="#cb3-545" aria-hidden="true" tabindex="-1"></a><span class="in">    dists[i] = 1</span></span>
<span id="cb3-546"><a href="#cb3-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-547"><a href="#cb3-547" aria-hidden="true" tabindex="-1"></a><span class="in">    projs = sgemm(1.0, X_centered[i], segments, trans_b=True)</span></span>
<span id="cb3-548"><a href="#cb3-548" aria-hidden="true" tabindex="-1"></a><span class="in">    np.clip(projs / dists, 0, None, out=projs)</span></span>
<span id="cb3-549"><a href="#cb3-549" aria-hidden="true" tabindex="-1"></a><span class="in">    projs = np.power(projs, self.p)</span></span>
<span id="cb3-550"><a href="#cb3-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-551"><a href="#cb3-551" aria-hidden="true" tabindex="-1"></a><span class="in">    affinity[i] = projs.sum(axis=0)</span></span>
<span id="cb3-552"><a href="#cb3-552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-553"><a href="#cb3-553" aria-hidden="true" tabindex="-1"></a><span class="in">affinity = np.power((affinity + affinity.T) / counts, 1 / self.p)</span></span>
<span id="cb3-554"><a href="#cb3-554" aria-hidden="true" tabindex="-1"></a><span class="in">affinity -= 0.5 * affinity.max()</span></span>
<span id="cb3-555"><a href="#cb3-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-556"><a href="#cb3-556" aria-hidden="true" tabindex="-1"></a><span class="in">#Scale and exponentiate</span></span>
<span id="cb3-557"><a href="#cb3-557" aria-hidden="true" tabindex="-1"></a><span class="in">q10, q90 = np.quantile(affinity, [0.1, 0.9])</span></span>
<span id="cb3-558"><a href="#cb3-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-559"><a href="#cb3-559" aria-hidden="true" tabindex="-1"></a><span class="in">gamma = np.log(self.M) / (q90 - q10)</span></span>
<span id="cb3-560"><a href="#cb3-560" aria-hidden="true" tabindex="-1"></a><span class="in">affinity = np.exp(gamma * affinity)</span></span>
<span id="cb3-561"><a href="#cb3-561" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb3-562"><a href="#cb3-562" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-563"><a href="#cb3-563" aria-hidden="true" tabindex="-1"></a>\newpage  </span>
<span id="cb3-564"><a href="#cb3-564" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-565"><a href="#cb3-565" aria-hidden="true" tabindex="-1"></a><span class="fu"># References {.unnumbered}</span></span>
<span id="cb3-566"><a href="#cb3-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-567"><a href="#cb3-567" aria-hidden="true" tabindex="-1"></a>::: {#refs}</span>
<span id="cb3-568"><a href="#cb3-568" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb3-569"><a href="#cb3-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-570"><a href="#cb3-570" aria-hidden="true" tabindex="-1"></a><span class="fu"># Session information {.appendix .unnumbered}</span></span>
<span id="cb3-571"><a href="#cb3-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-572"><a href="#cb3-572" aria-hidden="true" tabindex="-1"></a><span class="in">```{r session-info}</span></span>
<span id="cb3-573"><a href="#cb3-573" aria-hidden="true" tabindex="-1"></a><span class="in">sessionInfo()</span></span>
<span id="cb3-574"><a href="#cb3-574" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
    <script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize || "1.2em",
          commentDelimiter: el.dataset.commentDelimiter || "//",
          lineNumber: el.dataset.lineNumber === "true" ? true : false,
          lineNumberPunc: el.dataset.lineNumberPunc || ":",
          noEnd: el.dataset.noEnd === "true" ? true : false,
          titlePrefix: el.dataset.captionPrefix || "Algorithm"
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        if (captionSpan !== null) {
          let captionPrefix = el.dataset.captionPrefix + " ";
          let captionNumber = "";
          if (el.dataset.pseudocodeNumber) {
            captionNumber = el.dataset.pseudocodeNumber + " ";
            if (el.dataset.chapterLevel) {
              captionNumber = el.dataset.chapterLevel + "." + captionNumber;
            }
          }
          captionSpan.innerHTML = captionPrefix + captionNumber;
        }
      });
    })(document);
    </script>
  




</body></html>